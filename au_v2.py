# -*- coding: utf-8 -*-
"""
Amazon í˜¸ì£¼ ê°€ê²© ì¶”ì¶œ ì‹œìŠ¤í…œ V2 (íƒ€ì„ì¡´ ë¶„ë¦¬ ë²„ì „)
ì›ë³¸ au.py ê¸°ë°˜ - DB/íƒ€ì„ì¡´/íŒŒì¼ì„œë²„ ì„¤ì •ë§Œ V2ë¡œ ë³€ê²½
- í˜„ì§€ì‹œê°„(í˜¸ì£¼)ê³¼ í•œêµ­ì‹œê°„ ë¶„ë¦¬ ì €ì¥
- ìƒˆ ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© (DB_CONFIG_V2)
- í•µì‹¬ ë¡œì§ì€ ì›ë³¸ê³¼ ë™ì¼
"""
import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import pandas as pd
import pymysql
from sqlalchemy import create_engine
import paramiko
import time
import random
import re
from datetime import datetime
import pytz
import logging
import os
from io import StringIO
import json
import zipfile
import hashlib

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Import database configuration V2
from config import DB_CONFIG_V2 as DB_CONFIG

from config import FILE_SERVER_CONFIG

class AmazonAustraliaScraper:
    def __init__(self):
        self.driver = None
        self.db_engine = None
        self.country_code = 'au'
        self.wait = None
        # V2: íƒ€ì„ì¡´ ë¶„ë¦¬ (í˜„ì§€ì‹œê°„ + í•œêµ­ì‹œê°„)
        self.korea_tz = pytz.timezone('Asia/Seoul')
        self.local_tz = pytz.timezone('Australia/Canberra')  # í˜¸ì£¼ í˜„ì§€ ì‹œê°„ (ìº”ë²„ë¼)
        
        # DB ì—°ê²° ì„¤ì •
        self.setup_db_connection()
        
        # í˜¸ì£¼ ì „ìš© ì„ íƒì ì„¤ì •
        self.setup_australia_selectors()
        
        # DBì—ì„œ ì„ íƒì ë¡œë“œ (ë®ì–´ì“°ê¸°/ë³‘í•©)
        self.load_selectors_from_db()
        
    def setup_db_connection(self):
        """DB ì—°ê²° ì„¤ì •"""
        try:
            connection_string = (
                f"mysql+pymysql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@"
                f"{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}"
            )
            self.db_engine = create_engine(connection_string)
            logger.info("DB ì—°ê²° ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"DB ì—°ê²° ì‹¤íŒ¨: {e}")
            self.db_engine = None
    
    def setup_australia_selectors(self):
        """í˜¸ì£¼ ì „ìš© ì„ íƒì ì„¤ì •"""
        self.selectors = {
            'au': {
                'price': [
                    # ë©”ì¸ ê°€ê²© í‘œì‹œ ì˜ì—­ (a-offscreen ìš°ì„ )
                    "//*[@id='corePriceDisplay_desktop_feature_div']/div[1]/span[1]",
                    "//*[@id='corePrice_feature_div']//span[@class='a-offscreen']",
                    "//*[@id='corePriceDisplay_desktop_feature_div']//span[@class='a-offscreen']", 
                    ".a-price .a-offscreen",
                    "//span[@class='a-price']//span[@class='a-offscreen']",
                    
                    # ê°€ê²© whole ì„ íƒìë“¤
                    "//*[@id='corePrice_feature_div']//span[@class='a-price-whole']",
                    "//*[@id='corePrice_feature_div']/div/div/div/div/span[1]/span[1]",
                    "//*[@id='corePriceDisplay_desktop_feature_div']//span[@class='a-price-whole']",
                    "span.a-price-whole",
                    "//span[@class='a-price-whole']",
                    
                    # ë°±ì—… ì„ íƒìë“¤
                    "//span[@id='priceblock_ourprice']",
                    "//span[@id='priceblock_dealprice']",
                    ".a-price.a-text-price.a-size-medium .a-offscreen",
                    "span.a-price-range span.a-price-whole",
                    "div.a-section.a-spacing-micro span.a-price-whole"
                ],
                'price_fraction': [
                    "//*[@id='corePrice_feature_div']/div/div/div/div/span[1]/span[2]",
                    "//*[@id='corePriceDisplay_desktop_feature_div']/div[1]/span[3]/span[2]",
                    "//*[@id='corePrice_feature_div']//span[@class='a-price-fraction']",
                    "//*[@id='corePriceDisplay_desktop_feature_div']//span[@class='a-price-fraction']",
                    "//span[@class='a-price-fraction']",
                    ".a-price-fraction"
                ],
                'title': [
                    "#productTitle",
                    "//span[@id='productTitle']",
                    "//h1/span[@id='productTitle']",
                    "h1#title span",
                    "//div[@id='titleSection']//h1//span"
                ],
                'ships_from': [
                    # ê°œì„ ëœ ships_from ì„ íƒìë“¤
                    "//*[@id='SSOFpopoverLink_ubb']",
                    "//a[@id='SSOFpopoverLink_ubb']",
                    "//*[@id='fulfillerInfoFeature_feature_div']/div[2]/div[1]/span",
                    "//div[@id='fulfillerInfoFeature_feature_div']//span",
                    "//*[@id='fulfillerInfoFeature_feature_div']//div[2]//span",
                    "//div[contains(@id, 'fulfillerInfo')]//span",
                    "//span[contains(text(), 'Ships from')]/following-sibling::span",
                    "//div[@id='merchant-info']//a",
                    "//div[@tabular-attribute-name='Ships from']//span",
                    "//span[@class='tabular-buybox-text'][1]",
                    "//div[contains(@class, 'tabular-buybox-container')]//span[contains(text(), 'Ships from')]/../following-sibling::span",
                    "//div[@class='tabular-buybox-container']//span[@class='tabular-buybox-text']",
                    "//span[contains(text(), 'Dispatched from')]/../following-sibling::span"
                ],
                'sold_by': [
                    # ê°œì„ ëœ sold_by ì„ íƒìë“¤
                    "//a[@id='sellerProfileTriggerId']",
                    "//*[@id='sellerProfileTriggerId']",
                    "//*[@id='merchantInfoFeature_feature_div']/div[2]/div[1]/span",
                    "//div[@id='merchantInfoFeature_feature_div']//a",
                    "//div[@id='merchantInfoFeature_feature_div']//span",
                    "//*[@id='merchantInfoFeature_feature_div']//div[2]//span",
                    "//div[contains(@id, 'merchantInfo')]//span",
                    "//span[contains(text(), 'Sold by')]/following-sibling::a",
                    "//span[contains(text(), 'Sold by')]/following-sibling::span",
                    "//div[@tabular-attribute-name='Sold by']//span",
                    "//span[@class='tabular-buybox-text'][2]",
                    "//div[@id='fulfillerInfoFeature_feature_div']//a",
                    "//span[contains(text(), 'Sold by')]/../following-sibling::span//a"
                ],
                'imageurl': [
                    "//div[@id='imageBlock']//img[@id='landingImage']",
                    "//div[@id='main-image-container']//img",
                    "//img[@class='a-dynamic-image']",
                    "//div[@class='imgTagWrapper']//img",
                    "//div[@id='imageBlock_feature_div']//img",
                    "//img[@data-old-hires]"
                ],
                'availability': [
                    "//div[@id='availability']//span",
                    "//div[@id='availability_feature_div']//span",
                    "//span[@class='a-size-medium a-color-success']",
                    "//span[@class='a-size-medium a-color-price']",
                    "//div[@id='availability']//span[@class='a-size-medium']",
                    "//span[contains(text(), 'In stock')]",
                    "//span[contains(text(), 'Available')]"
                # ],
                # 'vat_text_list': [
                #     # í˜¸ì£¼ GST ë° ì„¸ê¸ˆ ê´€ë ¨ í…ìŠ¤íŠ¸
                #     "GST included", 
                #     "Tax included", 
                #     "VAT included", 
                #     "include VAT.",
                #     "Inclusive of all taxes",
                #     "Including all taxes",
                #     "Includes all taxes",
                #     "Price includes VAT",
                #     "Tax inclusive",
                #     "Including tax",
                #     "Inc. tax",
                #     "Incl. VAT",
                #     "Including GST",
                #     "GST inclusive",
                #     "All taxes included",
                #     "Price inclusive of taxes"
                ],
                'stock_flag': [
                    'Currently unavailable', 
                    'Out of Stock',
                    'Temporarily out of stock',
                    'Currently not available',
                    'This item is currently unavailable'
                ],
                'blocked_patterns': [
                    'sorry', 
                    'robot check', 
                    '503 Service Unavailable',
                    'Something went wrong',
                    'access denied',
                    'enter the characters',
                    'verify you are human',
                    'continue shopping',
                    'automated access'
                ]
            }
        }
    
    def load_selectors_from_db(self):
        """DBì—ì„œ ì„ íƒì ë¡œë“œ"""
        if not self.db_engine:
            logger.warning("DB ì—°ê²°ì´ ì—†ì–´ ì„ íƒì ë¡œë“œ ë¶ˆê°€")
            return
            
        try:
            query = """
            SELECT element_type, selector_value, priority
            FROM amazon_selectors
            WHERE country_code = %s 
              AND is_active = TRUE
              AND selector_value NOT LIKE '/html/%'
            ORDER BY element_type, priority ASC
            """
            
            df = pd.read_sql(query, self.db_engine, params=(self.country_code,))
            logger.info(f"DBì—ì„œ ì„ íƒì ë¡œë“œ: {len(df)}ê°œ")
            
            db_selectors = {self.country_code: {}}
            
            for element_type in df['element_type'].unique():
                db_selectors[self.country_code][element_type] = df[df['element_type'] == element_type]['selector_value'].tolist()
            
            for element_type, selectors in db_selectors[self.country_code].items():
                if element_type in self.selectors[self.country_code]:
                    existing = self.selectors[self.country_code][element_type]
                    self.selectors[self.country_code][element_type] = selectors + [s for s in existing if s not in selectors]
                else:
                    self.selectors[self.country_code][element_type] = selectors
            
            logger.info("DB ì„ íƒì ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"DB ì„ íƒì ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def setup_driver(self):
        """Chrome ë“œë¼ì´ë²„ ì„¤ì •"""
        logger.info("Chrome ë“œë¼ì´ë²„ ì„¤ì • ì¤‘ (í˜¸ì£¼ ì „ìš©)...")
        
        try:
            options = uc.ChromeOptions()
            
            options.add_argument('--disable-blink-features=AutomationControlled')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-setuid-sandbox')
            options.add_argument('--disable-web-security')
            options.add_argument('--disable-features=VizDisplayCompositor')
            
            # í˜¸ì£¼ ì „ìš© User-Agent
            user_agents = [
                'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
                'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            ]
            options.add_argument(f'--user-agent={random.choice(user_agents)}')
            
            # í˜¸ì£¼ ì–¸ì–´ ì„¤ì •
            options.add_experimental_option('prefs', {
                'intl.accept_languages': 'en-AU,en',
                'profile.default_content_settings.popups': 0,
                'profile.default_content_setting_values.notifications': 2
            })
            
            self.driver = uc.Chrome(options=options)
            self.driver.maximize_window()
            
            self.wait = WebDriverWait(self.driver, 20)
            
            logger.info("ë“œë¼ì´ë²„ ì„¤ì • ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"ë“œë¼ì´ë²„ ì„¤ì • ì‹¤íŒ¨: {e}")
            return False
    
    def handle_captcha_or_block_page(self):
        """ì°¨ë‹¨ í˜ì´ì§€ë‚˜ ìº¡ì°¨ ì²˜ë¦¬"""
        try:
            logger.info("ì°¨ë‹¨/ìº¡ì°¨ í˜ì´ì§€ í™•ì¸ ì¤‘...")
            
            continue_selectors = [
                "//button[contains(text(), 'Continue shopping')]",
                "//button[contains(@class, 'a-button-primary')]",
                "//input[@type='submit' and contains(@value, 'Continue')]",
                "//a[contains(text(), 'Continue shopping')]",
                "//span[contains(text(), 'Continue shopping')]/ancestor::button",
                "button.a-button-primary",
                "button[type='submit']",
                "#a-autoid-0",
                ".a-button-inner"
            ]
            
            for selector in continue_selectors:
                try:
                    logger.info(f"ë²„íŠ¼ ì°¾ê¸° ì‹œë„: {selector}")
                    
                    if selector.startswith('//'):
                        button = self.driver.find_element(By.XPATH, selector)
                    elif selector.startswith('#') or selector.startswith('.'):
                        button = self.driver.find_element(By.CSS_SELECTOR, selector)
                    else:
                        button = self.driver.find_element(By.CSS_SELECTOR, selector)
                    
                    if button and button.is_displayed():
                        button_text = button.text
                        logger.info(f"Continue ë²„íŠ¼ ë°œê²¬: {selector} (í…ìŠ¤íŠ¸: '{button_text}')")
                        
                        self.driver.execute_script("arguments[0].scrollIntoView();", button)
                        time.sleep(1)
                        
                        try:
                            button.click()
                            logger.info("ì¼ë°˜ í´ë¦­ ì„±ê³µ")
                        except:
                            try:
                                self.driver.execute_script("arguments[0].click();", button)
                                logger.info("JavaScript í´ë¦­ ì„±ê³µ")
                            except:
                                logger.warning("í´ë¦­ ì‹¤íŒ¨")
                                continue
                        
                        time.sleep(3)
                        logger.info("Continue ë²„íŠ¼ í´ë¦­ ì™„ë£Œ")
                        return True
                        
                except Exception as e:
                    logger.debug(f"ì„ íƒì ì˜¤ë¥˜: {e}")
                    continue
            
            # í…ìŠ¤íŠ¸ ê¸°ë°˜ ë²„íŠ¼ ê²€ìƒ‰
            try:
                logger.info("í…ìŠ¤íŠ¸ ê¸°ë°˜ ë²„íŠ¼ ê²€ìƒ‰...")
                buttons = self.driver.find_elements(By.TAG_NAME, "button")
                links = self.driver.find_elements(By.TAG_NAME, "a")
                inputs = self.driver.find_elements(By.TAG_NAME, "input")
                
                all_elements = buttons + links + inputs
                
                for element in all_elements:
                    try:
                        element_text = element.text.lower()
                        element_value = element.get_attribute('value')
                        if element_value:
                            element_value = element_value.lower()
                        else:
                            element_value = ""
                        
                        patterns = ['continue shopping', 'continue', 'shopping']
                        
                        for pattern in patterns:
                            if (pattern in element_text or pattern in element_value) and element.is_displayed():
                                logger.info(f"íŒ¨í„´ ë§¤ì¹­ ë²„íŠ¼ ë°œê²¬: '{element.text}' (íŒ¨í„´: {pattern})")
                                
                                self.driver.execute_script("arguments[0].scrollIntoView();", element)
                                time.sleep(1)
                                
                                try:
                                    element.click()
                                    logger.info("íŒ¨í„´ ë§¤ì¹­ í´ë¦­ ì„±ê³µ")
                                except:
                                    try:
                                        self.driver.execute_script("arguments[0].click();", element)
                                        logger.info("íŒ¨í„´ ë§¤ì¹­ JavaScript í´ë¦­ ì„±ê³µ")
                                    except:
                                        continue
                                
                                time.sleep(3)
                                return True
                                
                    except Exception as e:
                        logger.debug(f"ìš”ì†Œ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                        continue
                        
            except Exception as e:
                logger.debug(f"í…ìŠ¤íŠ¸ ê¸°ë°˜ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            
            logger.debug("Continue ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return False
            
        except Exception as e:
            logger.error(f"ì°¨ë‹¨ í˜ì´ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def is_page_blocked(self):
        """í˜ì´ì§€ ì°¨ë‹¨ ê°ì§€"""
        try:
            page_title = self.driver.title.lower()
            page_source = self.driver.page_source.lower()
            current_url = self.driver.current_url.lower()
            
            # ì •ìƒ í˜ì´ì§€ í™•ì¸ (ìš°ì„  ì²´í¬)
            normal_indicators = [
                'add to cart',
                'buy now',
                'product title',
                'price',
                'availability',
                'customer reviews',
                'product details',
                'ships from',
                'sold by'
            ]
            
            normal_count = sum(1 for indicator in normal_indicators if indicator in page_source)
            
            # ì •ìƒ ì§€í‘œê°€ 3ê°œ ì´ìƒì´ë©´ ì •ìƒ í˜ì´ì§€
            if normal_count >= 3:
                logger.info(f"ì •ìƒ í˜ì´ì§€ í™•ì¸: {normal_count}ê°œ ì§€í‘œ ë°œê²¬")
                return False
            
            serious_blocked_indicators = {
                'title': [
                    '503',
                    'access denied',
                    'error has occurred'
                ],
                'content': [
                    'enter the characters',
                    'verify you are human',
                    'access denied',
                    'automated access',
                    'suspicious activity'
                ]
            }
            
            for pattern in serious_blocked_indicators['title']:
                if pattern in page_title:
                    logger.warning(f"ì‹¬ê°í•œ ì°¨ë‹¨ ê°ì§€ (ì œëª©): {pattern}")
                    return True
            
            if ('continue shopping' not in page_source):
                for pattern in serious_blocked_indicators['content']:
                    if pattern in page_source:
                        logger.warning(f"ì‹¬ê°í•œ ì°¨ë‹¨ ê°ì§€ (ë³¸ë¬¸): {pattern}")
                        return True
            
            if 'amazon.com.au' not in current_url:
                logger.warning(f"Amazon Australia í˜ì´ì§€ê°€ ì•„ë‹˜: {current_url}")
                return True
            
            return False
            
        except Exception as e:
            logger.error(f"í˜ì´ì§€ ì°¨ë‹¨ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def wait_for_page_load(self, timeout=10):
        """í˜ì´ì§€ ë¡œë“œ ëŒ€ê¸°"""
        try:
            self.wait.until(
                lambda driver: driver.execute_script("return document.readyState") == "complete"
            )
            
            possible_elements = [
                (By.ID, "productTitle"),
                (By.ID, "priceblock_ourprice"),
                (By.CLASS_NAME, "a-price-whole"),
                (By.ID, "availability"),
                (By.ID, "imageBlock")
            ]
            
            for by, value in possible_elements:
                try:
                    WebDriverWait(self.driver, 3).until(
                        EC.presence_of_element_located((by, value))
                    )
                    logger.debug(f"ìš”ì†Œ ë°œê²¬: {by}={value}")
                    return True
                except:
                    continue
            
            return True
            
        except Exception as e:
            logger.warning(f"í˜ì´ì§€ ë¡œë“œ ëŒ€ê¸° ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def extract_element_text(self, selectors, element_name="ìš”ì†Œ"):
        """ì„ íƒì ëª©ë¡ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        logger.info(f"{element_name} ì¶”ì¶œ ì‹œì‘ - ì´ {len(selectors)}ê°œ ì„ íƒì")
        
        for idx, selector in enumerate(selectors, 1):
            try:
                logger.info(f"[{idx}/{len(selectors)}] ì‹œë„ ì¤‘: {selector}")
                
                if selector.startswith('//') or selector.startswith('('):
                    elements = self.driver.find_elements(By.XPATH, selector)
                    selector_type = "XPath"
                else:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    selector_type = "CSS"
                
                logger.info(f"íƒ€ì…: {selector_type}, ë°œê²¬: {len(elements)}ê°œ")
                
                if elements:
                    for i, element in enumerate(elements):
                        try:
                            if element.is_displayed():
                                text1 = element.text.strip()
                                text2 = element.get_attribute('textContent')
                                text3 = element.get_attribute('innerText')
                                
                                text2 = text2.strip() if text2 else ""
                                text3 = text3.strip() if text3 else ""
                                
                                text = max([text1, text2, text3], key=len)
                                
                                if text:
                                    logger.info(f"ì›ë³¸ í…ìŠ¤íŠ¸: '{text}'")
                                    
                                    if element_name in ["Sold By", "Ships From"]:
                                        label_only_patterns = [
                                            'sold by',
                                            'ships from'
                                        ]
                                        
                                        text_lower = text.lower().strip()
                                        
                                        if text_lower in label_only_patterns:
                                            logger.info(f"ë¼ë²¨ë§Œ ìˆìŒ, ìŠ¤í‚µ: '{text}'")
                                            continue
                                        
                                        for pattern in label_only_patterns:
                                            if text_lower.startswith(pattern + ' '):
                                                actual_value = text[len(pattern):].strip()
                                                if actual_value:
                                                    text = actual_value
                                                    logger.info(f"ë¼ë²¨ ì œê±° í›„: '{text}'")
                                                break
                                    
                                    if text:
                                        logger.info(f"ìµœì¢… ì¶”ì¶œ: '{text}'")
                                        return text
                        except Exception as e:
                            logger.debug(f"ìš”ì†Œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                
            except Exception as e:
                logger.debug(f"ì„ íƒì ì˜¤ë¥˜: {str(e)}")
                continue
        
        logger.error(f"{element_name} ì¶”ì¶œ ì™„ì „ ì‹¤íŒ¨")
        return None
    
    def parse_aud_price(self, price_text):
        """í˜¸ì£¼ ë‹¬ëŸ¬ ê°€ê²© íŒŒì‹±"""
        try:
            price_text = price_text.strip()
            logger.debug(f"íŒŒì‹±í•  ê°€ê²© í…ìŠ¤íŠ¸: '{price_text}'")
            
            # AUD ê¸°í˜¸ì™€ ê³µë°± ì œê±°
            cleaned = re.sub(r'[A$\s]', '', price_text)
            logger.debug(f"í†µí™” ì œê±° í›„: '{cleaned}'")
            
            # ì²œë‹¨ìœ„ ì½¤ë§ˆê°€ ìˆëŠ” ê²½ìš° ì œê±°í•˜ê³  ì†Œìˆ˜ì  ì²˜ë¦¬
            if re.match(r'^\d{1,3}(,\d{3})*(\.\d{1,2})?$', cleaned):
                cleaned = cleaned.replace(',', '')
                logger.debug(f"ì½¤ë§ˆ ì œê±° í›„: '{cleaned}'")
                
                if re.match(r'^\d+(\.\d{1,2})?$', cleaned):
                    return cleaned
            
            # ë‹¨ìˆœ ìˆ«ì íŒ¨í„´
            elif re.match(r'^\d+(\.\d{1,2})?$', cleaned):
                return cleaned
                    
        except Exception as e:
            logger.debug(f"ê°€ê²© íŒŒì‹± ì˜¤ë¥˜: {price_text} - {e}")
            
        return None
    
    def extract_price(self):
        """ê°€ê²© ì¶”ì¶œ"""
        logger.info(f"ê°€ê²© ì¶”ì¶œ ì‹œì‘ - êµ­ê°€: {self.country_code}")
        
        logger.info("1ë‹¨ê³„: a-offscreen ìš”ì†Œì—ì„œ ì™„ì „í•œ ê°€ê²© ì¶”ì¶œ ì‹œë„")
        offscreen_selectors = [
            "//*[@id='corePrice_feature_div']//span[@class='a-offscreen']",
            "//*[@id='corePriceDisplay_desktop_feature_div']//span[@class='a-offscreen']", 
            ".a-price .a-offscreen",
            "//span[@class='a-price']//span[@class='a-offscreen']"
        ]
        
        for selector in offscreen_selectors:
            try:
                logger.info(f"ì‹œë„: {selector}")
                if selector.startswith('//'):
                    elements = self.driver.find_elements(By.XPATH, selector)
                else:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                
                for element in elements:
                    if element.is_displayed():
                        text_methods = [
                            element.get_attribute('textContent'),
                            element.get_attribute('innerText'),
                            element.text
                        ]
                        
                        for text in text_methods:
                            if text and text.strip():
                                price_text = text.strip()
                                logger.info(f"ë°œê²¬ëœ í…ìŠ¤íŠ¸: {price_text}")
                                
                                price = self.parse_aud_price(price_text)
                                if price:
                                    logger.info(f"a-offscreenì—ì„œ ì™„ì „í•œ ê°€ê²© ì¶”ì¶œ ì„±ê³µ: {price}")
                                    return price
                                    
            except Exception as e:
                logger.debug(f"ì˜¤ë¥˜: {e}")
        
        logger.info("2ë‹¨ê³„: whole + fraction ì¡°í•©ìœ¼ë¡œ ê°€ê²© êµ¬ì„±")
        
        combination_attempts = [
            {
                'whole': "//*[@id='corePrice_feature_div']//span[@class='a-price-whole']",
                'fraction': "//*[@id='corePrice_feature_div']/div/div/div/div/span[1]/span[2]"
            },
            {
                'whole': "//*[@id='corePriceDisplay_desktop_feature_div']//span[@class='a-price-whole']",
                'fraction': "//*[@id='corePriceDisplay_desktop_feature_div']/div[1]/span[3]/span[2]"
            },
            {
                'whole': "//*[@id='corePrice_feature_div']//span[@class='a-price-whole']",
                'fraction': "//*[@id='corePrice_feature_div']//span[@class='a-price-fraction']"
            },
            {
                'whole': "//span[@class='a-price-whole']",
                'fraction': "//span[@class='a-price-fraction']"
            }
        ]
        
        for i, combo in enumerate(combination_attempts, 1):
            try:
                logger.info(f"ì¡°í•© ì‹œë„ {i}:")
                logger.info(f"ì •ìˆ˜ë¶€: {combo['whole']}")
                logger.info(f"ì†Œìˆ˜ë¶€: {combo['fraction']}")
                
                whole_elem = self.driver.find_element(By.XPATH, combo['whole'])
                fraction_elem = self.driver.find_element(By.XPATH, combo['fraction'])
                
                if whole_elem and fraction_elem and whole_elem.is_displayed() and fraction_elem.is_displayed():
                    whole_text = whole_elem.text.strip()
                    fraction_text = fraction_elem.text.strip()
                    
                    logger.info(f"ì •ìˆ˜ë¶€ í…ìŠ¤íŠ¸: {whole_text}")
                    logger.info(f"ì†Œìˆ˜ë¶€ í…ìŠ¤íŠ¸: {fraction_text}")
                    
                    if whole_text and fraction_text:
                        fraction_clean = re.sub(r'[^\d]', '', fraction_text)
                        if fraction_clean:
                            combined_price = f"{whole_text}.{fraction_clean}"
                            logger.info(f"ì¡°í•©ëœ ê°€ê²©: {combined_price}")
                            
                            price = self.parse_aud_price(combined_price)
                            if price:
                                logger.info(f"ì¡°í•© ê°€ê²© ì¶”ì¶œ ì„±ê³µ: {price}")
                                return price
                                
            except Exception as e:
                logger.debug(f"ì¡°í•© {i} ì˜¤ë¥˜: {e}")
        
        logger.info("3ë‹¨ê³„: ê°œë³„ ê°€ê²© ì„ íƒì ì‹œë„")
        price_selectors = self.selectors[self.country_code].get('price', [])
        
        for idx, selector in enumerate(price_selectors, 1):
            try:
                logger.info(f"[{idx}/{len(price_selectors)}] ì‹œë„: {selector}")
                
                if selector.startswith('//'):
                    elements = self.driver.find_elements(By.XPATH, selector)
                else:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                
                for element in elements:
                    if element.is_displayed():
                        text_methods = [
                            element.get_attribute('textContent'),
                            element.get_attribute('innerText'),
                            element.text
                        ]
                        
                        for text in text_methods:
                            if text and text.strip():
                                price_text = text.strip()
                                logger.info(f"í…ìŠ¤íŠ¸: {price_text}")
                                
                                price = self.parse_aud_price(price_text)
                                if price:
                                    logger.info(f"ê°œë³„ ì„ íƒì ê°€ê²© ì¶”ì¶œ ì„±ê³µ: {price}")
                                    return price
                                    
            except Exception as e:
                logger.debug(f"ì„ íƒì ì˜¤ë¥˜: {e}")
        
        logger.error("ëª¨ë“  ë°©ë²•ìœ¼ë¡œ ê°€ê²© ì¶”ì¶œ ì‹¤íŒ¨")
        return None
    
    def check_stock_availability(self):
        """ì¬ê³  ìƒíƒœ í™•ì¸"""
        try:
            try:
                availability_elem = self.driver.find_element(By.ID, "availability")
                availability_text = availability_elem.text.lower()
                
                if any(phrase in availability_text for phrase in [
                    'currently unavailable',
                    'out of stock',
                    'temporarily out of stock'
                ]):
                    logger.info(f"ì¬ê³  ì—†ìŒ: {availability_text}")
                    return False
                    
                if any(phrase in availability_text for phrase in [
                    'in stock',
                    'only',
                    'left in stock'
                ]):
                    logger.info(f"ì¬ê³  ìˆìŒ: {availability_text}")
                    return True
                    
            except NoSuchElementException:
                logger.debug("availability ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            
            buy_buttons = [
                "add-to-cart-button",
                "buy-now-button",
                "add-to-cart-button-ubb"
            ]
            
            for button_id in buy_buttons:
                try:
                    button = self.driver.find_element(By.ID, button_id)
                    if button and button.is_enabled():
                        logger.info("êµ¬ë§¤ ë²„íŠ¼ í™œì„±í™” - ì¬ê³  ìˆìŒ")
                        return True
                except:
                    continue
            
            logger.info("ì¬ê³  ìƒíƒœ ë¶ˆëª…í™• - ê¸°ë³¸ê°’: ì¬ê³  ìˆìŒ")
            return True
            
        except Exception as e:
            logger.warning(f"ì¬ê³  í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return True
    
    def extract_product_info(self, url, row_data, retry_count=0, max_retries=3):
        """ì œí’ˆ ì •ë³´ ì¶”ì¶œ"""
        try:
            logger.info("=" * 60)
            logger.info("í˜¸ì£¼ ì œí’ˆ ì •ë³´ ì¶”ì¶œ ì‹œì‘")
            logger.info(f"URL: {url}")
            logger.info(f"ë¸Œëœë“œ: {row_data.get('brand', 'N/A')}")
            logger.info(f"ì œí’ˆ: {row_data.get('item', 'N/A')}")
            
            self.driver.get(url)
            time.sleep(random.uniform(2, 4))
            
            page_source_lower = self.driver.page_source.lower()
            if ('continue shopping' in page_source_lower or 
                'click the button below' in page_source_lower):
                logger.info("ì°¨ë‹¨/ìº¡ì°¨ í˜ì´ì§€ ê°ì§€ - Continue ë²„íŠ¼ ì°¾ëŠ” ì¤‘...")
                if self.handle_captcha_or_block_page():
                    time.sleep(3)
                    self.wait_for_page_load()
                else:
                    logger.warning("Continue ë²„íŠ¼ í´ë¦­ ì‹¤íŒ¨")
            
            self.wait_for_page_load()
            
            if self.is_page_blocked():
                logger.error("ì—¬ì „íˆ ì°¨ë‹¨ í˜ì´ì§€ì„")
                raise Exception("í˜ì´ì§€ ì°¨ë‹¨ë¨")
            
            # V2: íƒ€ì„ì¡´ ë¶„ë¦¬

            
            now_time = datetime.now(self.korea_tz)

            
            local_time = datetime.now(self.local_tz)

            # ISO 8601 í˜•ì‹
            crawl_dt = local_time.strftime("%Y-%m-%dT%H:%M:%S")
            tz_offset = local_time.strftime("%z")
            tz_formatted = f"{tz_offset[:3]}:{tz_offset[3:]}" if tz_offset else "+00:00"
            crawl_datetime_iso = f"{crawl_dt}{tz_formatted}"

            result = {
                'retailerid': row_data.get('retailerid', ''),
                'country_code': self.country_code,
                'ships_from': None,
                'channel': row_data.get('channel', 'Online'),
                'retailersku': row_data.get('retailersku', ''),
                'brand': row_data.get('brand', ''),
                'brand_eng': row_data.get('brand_eng', row_data.get('brand', '')),
                'form_factor': row_data.get('form_factor', ''),
                'segment_lv1': row_data.get('seg_lv1', ''),
                'segment_lv2': row_data.get('seg_lv2', ''),
                'segment_lv3': row_data.get('seg_lv3', ''),
                'capacity': row_data.get('capacity', ''),
                'item': row_data.get('item', ''),
                'retailprice': None,
                'sold_by': None,
                'imageurl': None,
                'producturl': url,
                'crawl_datetime': crawl_datetime_iso,
                'kr_crawl_datetime': now_time.strftime('%Y-%m-%d %H:%M:%S'),  # V2: í•œêµ­ì‹œê°„
                'kr_crawl_strdatetime': now_time.strftime('%Y%m%d%H%M%S') + f"{now_time.microsecond:06d}"[:4],  # V2: í•œêµ­ì‹œê°„ ë¬¸ìì—´
                'crawl_strdatetime': local_time.strftime('%Y%m%d%H%M%S') + f"{local_time.microsecond:06d}"[:4],
                'title': None,
                'vat': row_data.get('vat', 'x')
            }
            
            result['title'] = self.extract_element_text(
                self.selectors[self.country_code].get('title', []), 
                "ì œëª©"
            )
            
            has_stock = self.check_stock_availability()
            
            # Ships From ì¶”ì¶œ
            result['ships_from'] = self.extract_element_text(
                self.selectors[self.country_code].get('ships_from', []), 
                "Ships From"
            )
            
            # Sold By ì¶”ì¶œ
            result['sold_by'] = self.extract_element_text(
                self.selectors[self.country_code].get('sold_by', []), 
                "Sold By"
            )
            
            # Ships Fromê³¼ Sold Byê°€ ëª¨ë‘ ì—†ìœ¼ë©´ ê°€ê²©ë„ ë¹ˆ ê°’ìœ¼ë¡œ ì²˜ë¦¬
            if not result['ships_from'] and not result['sold_by']:
                logger.warning("Ships Fromê³¼ Sold Byê°€ ëª¨ë‘ ì—†ìŒ - ê°€ê²©ì„ ë¹ˆ ê°’ìœ¼ë¡œ ì„¤ì •")
                result['retailprice'] = None
            else:
                logger.info("ê°€ê²© ì¶”ì¶œ ì‹œë„")
                result['retailprice'] = self.extract_price()
                
                if not has_stock and result['retailprice'] is None:
                    result['retailprice'] = None
                    logger.info("ì¬ê³  ì—†ìŒ + ê°€ê²© ì—†ìŒ -> ê°€ê²© Noneìœ¼ë¡œ ì„¤ì •")
            
            for selector in self.selectors[self.country_code].get('imageurl', []):
                try:
                    if selector.startswith('//'):
                        element = self.driver.find_element(By.XPATH, selector)
                    else:
                        element = self.driver.find_element(By.CSS_SELECTOR, selector)
                    
                    result['imageurl'] = element.get_attribute('src')
                    if result['imageurl']:
                        logger.debug("ì´ë¯¸ì§€ URL ì¶”ì¶œ ì„±ê³µ")
                        break
                except:
                    continue
            
            page_source = self.driver.page_source
            page_source_lower = page_source.lower()
            
            # for vat_text in self.selectors[self.country_code].get('vat_text_list', []):
            #     if vat_text.lower() in page_source_lower:
            #         result['vat'] = 'o'
            #         logger.info(f"VAT/Tax í¬í•¨ í™•ì¸: {vat_text}")
            #         break
            
            logger.info("ì¶”ì¶œ ê²°ê³¼:")
            logger.info(f"ì œëª©: {result['title'][:50] + '...' if result['title'] and len(result['title']) > 50 else result['title']}")
            logger.info(f"ê°€ê²©: {result['retailprice']}")
            logger.info(f"ì´ë¯¸ì§€: {'ìˆìŒ' if result['imageurl'] else 'ì—†ìŒ'}")
            logger.info(f"íŒë§¤ì: {result['sold_by']}")
            logger.info(f"ë°°ì†¡ì§€: {result['ships_from']}")
            # logger.info(f"VAT: {result['vat']}")
            
            return result
            
        except Exception as e:
            logger.error(f"í˜ì´ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            
            if retry_count < max_retries:
                wait_time = (retry_count + 1) * 10
                logger.info(f"{wait_time}ì´ˆ í›„ ì¬ì‹œë„... ({retry_count + 1}/{max_retries})")
                time.sleep(wait_time)
                
                try:
                    self.driver.refresh()
                except:
                    logger.info("ë“œë¼ì´ë²„ ì¬ì‹œì‘ ì¤‘...")
                    self.driver.quit()
                    self.setup_driver()
                
                return self.extract_product_info(url, row_data, retry_count + 1, max_retries)
            
            # V2: íƒ€ì„ì¡´ ë¶„ë¦¬

            
            now_time = datetime.now(self.korea_tz)

            
            local_time = datetime.now(self.local_tz)
            return {
                'retailerid': row_data.get('retailerid', ''),
                'country_code': self.country_code,
                'ships_from': None,
                'channel': row_data.get('channel', 'Online'),
                'retailersku': row_data.get('retailersku', ''),
                'brand': row_data.get('brand', ''),
                'brand_eng': row_data.get('brand_eng', row_data.get('brand', '')),
                'form_factor': row_data.get('form_factor', ''),
                'segment_lv1': row_data.get('seg_lv1', ''),
                'segment_lv2': row_data.get('seg_lv2', ''),
                'segment_lv3': row_data.get('seg_lv3', ''),
                'capacity': row_data.get('capacity', ''),
                'item': row_data.get('item', ''),
                'retailprice': None,
                'sold_by': None,
                'imageurl': None,
                'producturl': url,
                'crawl_datetime': crawl_datetime_iso,
                'kr_crawl_datetime': now_time.strftime('%Y-%m-%d %H:%M:%S'),  # V2: í•œêµ­ì‹œê°„
                'kr_crawl_strdatetime': now_time.strftime('%Y%m%d%H%M%S') + f"{now_time.microsecond:06d}"[:4],  # V2: í•œêµ­ì‹œê°„ ë¬¸ìì—´
                'crawl_strdatetime': local_time.strftime('%Y%m%d%H%M%S') + f"{local_time.microsecond:06d}"[:4],
                'title': None,
                'vat': row_data.get('vat', 'x')
            }
    
    def get_crawl_targets(self, limit=None):
        """DBì—ì„œ í¬ë¡¤ë§ ëŒ€ìƒ URL ëª©ë¡ ì¡°íšŒ"""
        try:
            query = f"""
            SELECT *
            FROM samsung_price_tracking_list
            WHERE country = '{self.country_code}' 
              AND mall_name = 'amazon'
              AND is_active = TRUE
            """
                
            if limit:
                query += f" LIMIT {limit}"
            
            df = pd.read_sql(query, self.db_engine)
            logger.info(f"í¬ë¡¤ë§ ëŒ€ìƒ {len(df)}ê°œ ì¡°íšŒ ì™„ë£Œ")
            return df.to_dict('records')
            
        except Exception as e:
            logger.error(f"í¬ë¡¤ë§ ëŒ€ìƒ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def save_to_db(self, df):
        """DBì— ê²°ê³¼ ì €ì¥"""
        if self.db_engine is None:
            logger.warning("DB ì—°ê²°ì´ ì—†ì–´ DB ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤")
            return False
        
        try:
            table_name = f'amazon_price_crawl_tbl_{self.country_code}_v2'
            
            df.to_sql(table_name, self.db_engine, if_exists='append', index=False)
            logger.info(f"DB ì €ì¥ ì™„ë£Œ: {len(df)}ê°œ ë ˆì½”ë“œ -> {table_name}")
            
            log_records = []
            for _, row in df.iterrows():
                log_records.append({
                    'country_code': self.country_code,
                    'url': row['producturl'],
                    'status': 'success' if row['retailprice'] is not None else 'failed',
                    'error_message': None if row['retailprice'] is not None else 'Price not found',
                    'execution_time': random.uniform(3, 10),
                    'retailprice': row['retailprice'],
                    'crawl_datetime': row['crawl_datetime']
                })
            
            if log_records:
                log_df = pd.DataFrame(log_records)
                log_df.to_sql('amazon_crawl_logs', self.db_engine, if_exists='append', index=False)
                logger.info(f"í¬ë¡¤ë§ ë¡œê·¸ ì €ì¥ ì™„ë£Œ: {len(log_records)}ê°œ")
            
            return True
            
        except Exception as e:
            logger.error(f"DB ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def upload_to_file_server(self, local_file_path, date_folder):
        """íŒŒì¼ì„œë²„ì— ì—…ë¡œë“œ"""
        try:
            transport = paramiko.Transport((FILE_SERVER_CONFIG['host'], FILE_SERVER_CONFIG['port']))
            transport.connect(
                username=FILE_SERVER_CONFIG['username'],
                password=FILE_SERVER_CONFIG['password']
            )
            sftp = paramiko.SFTPClient.from_transport(transport)

            # êµ­ê°€ë³„ ë””ë ‰í† ë¦¬ ê²½ë¡œ
            country_dir = f"{FILE_SERVER_CONFIG['upload_path']}/{self.country_code}"

            # êµ­ê°€ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
            try:
                sftp.stat(country_dir)
            except FileNotFoundError:
                logger.info(f"ğŸ“ êµ­ê°€ ë””ë ‰í† ë¦¬ ìƒì„±: {country_dir}")
                sftp.mkdir(country_dir)

            # ë‚ ì§œë³„ ë””ë ‰í† ë¦¬ ê²½ë¡œ
            date_dir = f"{country_dir}/{date_folder}"

            # ë‚ ì§œ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
            try:
                sftp.stat(date_dir)
            except FileNotFoundError:
                logger.info(f"ğŸ“ ë‚ ì§œ ë””ë ‰í† ë¦¬ ìƒì„±: {date_dir}")
                sftp.mkdir(date_dir)

            # ì—…ë¡œë“œ ê²½ë¡œ
            remote_filename = os.path.basename(local_file_path)
            remote_path = f"{date_dir}/{remote_filename}"

            # íŒŒì¼ ì—…ë¡œë“œ
            sftp.put(local_file_path, remote_path)
            logger.info(f"âœ… íŒŒì¼ì„œë²„ ì—…ë¡œë“œ ì™„ë£Œ: {remote_path}")

            sftp.close()
            transport.close()

            return True
        except Exception as e:
            logger.error(f"âŒ íŒŒì¼ì„œë²„ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    def save_results(self, df, save_db=True, upload_server=True):
        """ê²°ê³¼ ì €ì¥"""
        now = datetime.now(self.korea_tz)
        date_str = now.strftime('%Y%m%d')
        time_str = now.strftime('%H%M%S')
        base_filename = f"{date_str}_{time_str}_au_amazon"

        results = {'db_saved': False, 'server_uploaded': False}

        if save_db:
            results['db_saved'] = self.save_to_db(df)

        if upload_server:
            try:
                # 1. CSV íŒŒì¼ ìƒì„±
                csv_filename = f'{base_filename}.csv'
                # Headerë¥¼ ëŒ€ë¬¸ìë¡œ ë³€í™˜
                df.columns = df.columns.str.upper()
                df.to_csv(csv_filename, index=False, encoding='utf-8', lineterminator='\r\n')

                # 2. CSVë¥¼ ZIPìœ¼ë¡œ ì••ì¶•
                zip_filename = f'{base_filename}.zip'
                with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:
                    zipf.write(csv_filename, arcname=csv_filename)

                # 3. MD5 ê³„ì‚°
                def calculate_md5(filename):
                    md5 = hashlib.md5()
                    with open(filename, 'rb') as f:
                        for chunk in iter(lambda: f.read(4096), b''):
                            md5.update(chunk)
                    return md5.hexdigest()

                csv_md5 = calculate_md5(csv_filename)
                zip_md5 = calculate_md5(zip_filename)

                # 4. MD5 íŒŒì¼ ìƒì„± (ì •í•©ì„± í™•ì¸)
                md5_filename = f'{base_filename}.md5'
                with open(md5_filename, 'w', encoding='utf-8') as f:
                    f.write(f"{os.path.basename(zip_filename)} {zip_md5}\n")
                    f.write(f"{os.path.basename(csv_filename)} {csv_md5}\n")

                # 5. ZIPê³¼ MD5ë¥¼ ë‚ ì§œ í´ë”ì— ì—…ë¡œë“œ
                if self.upload_to_file_server(zip_filename, date_str):
                    if self.upload_to_file_server(md5_filename, date_str):
                        results['server_uploaded'] = True

                # 6. ë¡œì»¬ ì„ì‹œ íŒŒì¼ ì‚­ì œ
                for temp_file in [csv_filename, zip_filename, md5_filename]:
                    if os.path.exists(temp_file):
                        os.remove(temp_file)

                logger.info("ì„ì‹œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")

        return results
    def scrape_urls(self, urls_data, max_items=None):
        """ì—¬ëŸ¬ URL ìŠ¤í¬ë˜í•‘"""
        if max_items:
            urls_data = urls_data[:max_items]
        
        logger.info("=" * 80)
        logger.info("í˜¸ì£¼ í¬ë¡¤ë§ ì‹œì‘")
        logger.info(f"êµ­ê°€: {self.country_code.upper()}")
        logger.info(f"ëŒ€ìƒ: {len(urls_data)}ê°œ ì œí’ˆ")
        logger.info("=" * 80)
        
        if not self.setup_driver():
            logger.error("ë“œë¼ì´ë²„ ì„¤ì • ì‹¤íŒ¨")
            return None
        
        results = []
        failed_urls = []
        
        try:
            for idx, row in enumerate(urls_data):
                logger.info(f"ì§„í–‰ë¥ : {idx + 1}/{len(urls_data)} ({(idx + 1)/len(urls_data)*100:.1f}%)")
                
                url = row.get('url')
                
                result = self.extract_product_info(url, row)
                
                if result['retailprice'] is None and result['title'] is None:
                    failed_urls.append({
                        'url': url,
                        'item': row.get('item', ''),
                        'brand': row.get('brand', ''),
                        'reason': 'ê°€ê²©ê³¼ ì œëª© ëª¨ë‘ ì—†ìŒ'
                    })
                elif result['retailprice'] is None:
                    failed_urls.append({
                        'url': url,
                        'item': row.get('item', ''),
                        'brand': row.get('brand', ''),
                        'reason': 'ê°€ê²© ì—†ìŒ'
                    })
                
                results.append(result)
                
                if (idx + 1) % 10 == 0:
                    interim_df = pd.DataFrame(results[-10:])
                    if self.db_engine:
                        try:
                            table_name = f'amazon_price_crawl_tbl_{self.country_code}_v2'
                            interim_df.to_sql(table_name, self.db_engine, 
                                            if_exists='append', index=False)
                            logger.info("ì¤‘ê°„ ì €ì¥: 10ê°œ ë ˆì½”ë“œ DB ì €ì¥")
                        except Exception as e:
                            logger.error(f"ì¤‘ê°„ ì €ì¥ ì‹¤íŒ¨: {e}")
                
                if idx < len(urls_data) - 1:
                    wait_time = random.uniform(5, 10)
                    logger.info(f"{wait_time:.1f}ì´ˆ ëŒ€ê¸° ì¤‘...")
                    time.sleep(wait_time)
                    
                    if (idx + 1) % 20 == 0:
                        logger.info("20ê°œ ì²˜ë¦¬ ì™„ë£Œ, 30ì´ˆ íœ´ì‹...")
                        time.sleep(30)
        
        except Exception as e:
            logger.error(f"ìŠ¤í¬ë˜í•‘ ì¤‘ ì˜¤ë¥˜: {e}")
        
        finally:
            if failed_urls:
                logger.warning(f"ë¬¸ì œ ë°œìƒí•œ URL {len(failed_urls)}ê°œ:")
                for fail in failed_urls[:5]:
                    logger.warning(f"  - {fail['brand']} {fail['item']}: {fail.get('reason', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                if len(failed_urls) > 5:
                    logger.warning(f"  ... ì™¸ {len(failed_urls) - 5}ê°œ")
            
            if self.driver:
                self.driver.quit()
                logger.info("ë“œë¼ì´ë²„ ì¢…ë£Œ")
        
        return pd.DataFrame(results)
    
    def analyze_results(self, df):
        """ê²°ê³¼ ë¶„ì„"""
        logger.info("=" * 80)
        logger.info("ê²°ê³¼ ë¶„ì„")
        logger.info("=" * 80)
        
        total = len(df)
        with_price = df['retailprice'].notna().sum()
        without_price = df['retailprice'].isna().sum()
        success_rate = (with_price / total * 100) if total > 0 else 0
        
        logger.info(f"ì „ì²´ ì œí’ˆ: {total}ê°œ")
        logger.info(f"ê°€ê²© ì¶”ì¶œ ì„±ê³µ: {with_price}ê°œ")
        logger.info(f"ê°€ê²© ì¶”ì¶œ ì‹¤íŒ¨: {without_price}ê°œ")
        logger.info(f"ì„±ê³µë¥ : {success_rate:.1f}%")
        
        if with_price > 0:
            price_df = df[df['retailprice'].notna()].copy()
            
            try:
                price_df['price_numeric'] = price_df['retailprice'].astype(str).str.replace(',', '').astype(float)
                
                logger.info("ê°€ê²© í†µê³„:")
                logger.info(f"   í‰ê· ê°€: {price_df['price_numeric'].mean():.2f}")
                logger.info(f"   ìµœì €ê°€: {price_df['price_numeric'].min():.2f}")
                logger.info(f"   ìµœê³ ê°€: {price_df['price_numeric'].max():.2f}")
                logger.info(f"   ì¤‘ê°„ê°’: {price_df['price_numeric'].median():.2f}")
            except Exception as e:
                logger.warning(f"ê°€ê²© í†µê³„ ê³„ì‚° ì˜¤ë¥˜: {e}")
                logger.info("ê°€ê²© í†µê³„: ê³„ì‚° ë¶ˆê°€ (ë¬¸ìì—´ í˜•íƒœ ê°€ê²©)")
            
            brand_stats = df.groupby('brand').agg({
                'retailprice': ['count', lambda x: x.notna().sum()]
            })
            brand_stats.columns = ['total', 'success']
            brand_stats['success_rate'] = (brand_stats['success'] / brand_stats['total'] * 100).round(1)
            
            logger.info("ë¸Œëœë“œë³„ ì„±ê³µë¥ :")
            for brand, row in brand_stats.iterrows():
                logger.info(f"   {brand}: {row['success_rate']:.1f}% ({row['success']}/{row['total']})")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    test_mode = os.getenv('TEST_MODE', 'false').lower() == 'true'
    max_items = int(os.getenv('MAX_ITEMS', '0')) or None
    
    print("=" * 80)
    print("Amazon Australia ê°€ê²© ì¶”ì¶œ ì‹œìŠ¤í…œ v1.0")
    print("=" * 80)
    print(f"êµ­ê°€: Australia")
    print(f"ëª¨ë“œ: {'í…ŒìŠ¤íŠ¸' if test_mode else 'ì‹¤ì œ'}")
    print("íŠ¹ì§•: ships_fromê³¼ sold_by ëª¨ë‘ ì—†ì„ ê²½ìš° ê°€ê²© None ì²˜ë¦¬")
    print("ê°€ê²© í˜•íƒœ: í˜¸ì£¼ ë‹¬ëŸ¬(AUD) ì™„ë²½ ì¶”ì¶œ")
    if max_items:
        print(f"ìµœëŒ€ ì²˜ë¦¬ ìˆ˜: {max_items}ê°œ")
    print("=" * 80)
    
    scraper = AmazonAustraliaScraper()
    
    if scraper.db_engine is None:
        logger.error("DB ì—°ê²° ì‹¤íŒ¨ë¡œ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    if test_mode:
        logger.info("í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì‹¤í–‰ ì¤‘...")
        test_data = [{
            'url': 'https://www.amazon.com.au/dp/B0CTRXBKHP',
            'brand': 'Crucial',
            'item': 'T705 1TB',
            'retailerid': 'TEST001',
            'retailersku': 'TEST001',
            'channel': 'Online',
            'seg_lv1': 'SSD',
            'seg_lv2': 'Consumer',
            'seg_lv3': 'NVMe',
            'capacity': '1TB',
            'form_factor': 'M.2'
        }]
        
        results_df = scraper.scrape_urls(test_data)
        if results_df is not None and not results_df.empty:
            scraper.analyze_results(results_df)
            scraper.save_results(results_df, save_db=False, upload_server=True)
        return
    
    logger.info("ì „ì²´ í¬ë¡¤ë§ ì‹œì‘")
    urls_data = scraper.get_crawl_targets(limit=max_items)
    
    if not urls_data:
        logger.warning("í¬ë¡¤ë§ ëŒ€ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    logger.info(f"í¬ë¡¤ë§ ëŒ€ìƒ: {len(urls_data)}ê°œ")
    
    results_df = scraper.scrape_urls(urls_data, max_items)
    
    if results_df is None or results_df.empty:
        logger.error("í¬ë¡¤ë§ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    scraper.analyze_results(results_df)
    
    save_results = scraper.save_results(
        results_df,
        save_db=True,
        upload_server=True
    )
    
    logger.info("=" * 80)
    logger.info("ì €ì¥ ê²°ê³¼")
    logger.info("=" * 80)
    logger.info(f"DB ì €ì¥: {'ì„±ê³µ' if save_results['db_saved'] else 'ì‹¤íŒ¨'}")
    logger.info(f"íŒŒì¼ì„œë²„ ì—…ë¡œë“œ: {'ì„±ê³µ' if save_results['server_uploaded'] else 'ì‹¤íŒ¨'}")
    
    logger.info("=" * 80)
    logger.info("í¬ë¡¤ë§ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ!")
    logger.info("=" * 80)

if __name__ == "__main__":
    required_packages = [
        'undetected-chromedriver',
        'selenium',
        'pandas',
        'pymysql',
        'sqlalchemy',
        'paramiko',
        'openpyxl'
    ]
    
    print("í•„ìš”í•œ íŒ¨í‚¤ì§€:")
    print("pip install " + " ".join(required_packages))
    print("í™˜ê²½ë³€ìˆ˜ ì„¤ì •:")
    print("export TEST_MODE=false  # í…ŒìŠ¤íŠ¸ ëª¨ë“œ")
    print("export MAX_ITEMS=10     # ìµœëŒ€ ì²˜ë¦¬ ê°œìˆ˜ (ì„ íƒì‚¬í•­)")
    print()
    
    main()