"""
Amazon ê°€ê²© ì¶”ì¶œ ì‹œìŠ¤í…œ V2 - ì¼ë³¸ ì•„ë§ˆì¡´ (íƒ€ì„ì¡´ ë¶„ë¦¬ ë²„ì „)
í•µì‹¬ ê°œì„ ì‚¬í•­:
1. í˜„ì§€ì‹œê°„(ì¼ë³¸)ê³¼ í•œêµ­ì‹œê°„ ë¶„ë¦¬ ì €ì¥
2. ë‚ ì§œë³„ ë””ë ‰í† ë¦¬ êµ¬ì¡° ë° ZIP ì••ì¶•
3. ìƒˆ ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© (samsung_ds_retail_com)

í•µì‹¬ ë¡œì§:
1. ships_fromê³¼ sold_by ë‘˜ ë‹¤ ë¹„ì–´ìˆìœ¼ë©´ ê°€ê²© 0
2. í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ê¸°ì¡´ ê°€ê²© ì¶”ì¶œ ë¡œì§ ì‚¬ìš©
3. ì°¨ë‹¨ í˜ì´ì§€ ê°ì§€ ì‹œ "ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã‚’ç¶šã‘ã‚‹" ë²„íŠ¼ í´ë¦­ í›„ ì›ë˜ URL ì¬ì‹œë„
4. ì¬ê³  í™•ì¸ ë“± ë³µì¡í•œ ë¡œì§ ì œê±°
"""
import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import pandas as pd
import pymysql
from sqlalchemy import create_engine
import paramiko
import time
import random
import re
from datetime import datetime
import pytz
import logging
import os
from io import StringIO
import json
import zipfile

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Import database configuration V2
from config import DB_CONFIG_V2 as DB_CONFIG

from config import FILE_SERVER_CONFIG

class AmazonScraper:
    def __init__(self, country_code='jp'):
        self.driver = None
        self.db_engine = None
        self.country_code = country_code.lower()
        self.wait = None

        # V2: íƒ€ì„ì¡´ ë¶„ë¦¬ (í˜„ì§€ì‹œê°„ + í•œêµ­ì‹œê°„)
        self.korea_tz = pytz.timezone('Asia/Seoul')
        self.local_tz = pytz.timezone('Asia/Tokyo')  # ì¼ë³¸ í‘œì¤€ì‹œ

        # DB ì—°ê²° ì„¤ì •
        self.setup_db_connection()

        # ê¸°ë³¸ ì„ íƒì ì„¤ì •
        self.setup_default_selectors()

        # DBì—ì„œ ì„ íƒì ë¡œë“œ (ë®ì–´ì“°ê¸°/ë³‘í•©)
        self.load_selectors_from_db()

    def setup_db_connection(self):
        """DB ì—°ê²° ì„¤ì •"""
        try:
            connection_string = (
                f"mysql+pymysql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@"
                f"{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}"
            )
            self.db_engine = create_engine(connection_string)
            logger.info("âœ… DB ì—°ê²° ì„¤ì • ì™„ë£Œ")

        except Exception as e:
            logger.error(f"âŒ DB ì—°ê²° ì‹¤íŒ¨: {e}")
            self.db_engine = None

    def setup_default_selectors(self):
        """ê¸°ë³¸ ì„ íƒì ì„¤ì • - ì•ˆì •ì ì¸ ìƒëŒ€ ê²½ë¡œ ì‚¬ìš©"""
        self.selectors = {
            self.country_code: {
                'price': [
                    # ê°€ì¥ ì¼ë°˜ì ì¸ ê°€ê²© ì„ íƒìë“¤
                    "span.a-price-whole",
                    "//span[@class='a-price-whole']",
                    "//span[contains(@class, 'a-price-whole')]",
                    ".a-price.a-text-price.a-size-medium .a-offscreen",
                    "//span[@class='a-price']//span[@class='a-offscreen']",
                    "//*[@id='corePriceDisplay_desktop_feature_div']//span[@class='a-price-whole']",
                    "//div[@class='a-section a-spacing-none aok-align-center']//span[@class='a-price-whole']",
                    "span.a-price-range span.a-price-whole",
                    "#apex_desktop .a-price-whole",
                    "div.a-section.a-spacing-micro span.a-price-whole",
                    "[data-a-color='price'] .a-offscreen",
                    ".a-price-range .a-price .a-offscreen"
                ],
                'title': [
                    "#productTitle",
                    "//span[@id='productTitle']",
                    "//h1/span[@id='productTitle']",
                    "h1#title span",
                    "//div[@id='titleSection']//h1//span"
                ],
                'ships_from': [
                    "//*[@id='fulfillerInfoFeature_feature_div']/div[2]/div[1]/span",
                    "/html/body/div[2]/div/div/div[4]/div[1]/div[3]/div/div[1]/div/div/div/form/div/div/div/div/div[4]/div/div[20]/div/div/div[1]/div/div[2]/div[2]/div[1]/span"
                ],
                'sold_by': [
                    "//*[@id='merchantInfoFeature_feature_div']/div[2]/div[1]/span/a",
                    "//*[@id='sellerProfileTriggerId']",
                    "/html/body/div[2]/div/div/div[4]/div[1]/div[3]/div/div[1]/div/div/div/form/div/div/div/div/div[4]/div/div[20]/div/div/div[1]/div/div[3]/div[2]/div[1]/a"
                ],
                'imageurl': [
                    "//div[@id='imageBlock']//img[@id='landingImage']",
                    "//div[@id='main-image-container']//img",
                    "//img[@class='a-dynamic-image']",
                    "//div[@class='imgTagWrapper']//img"
                ],
                'availability': [
                    "//div[@id='availability']//span",
                    "//div[@id='availability_feature_div']//span",
                    "//span[@class='a-size-medium a-color-success']",
                    "//span[@class='a-size-medium a-color-price']"
                ],
                'stock_flag': [
                    'Currently unavailable',
                    'Out of Stock',
                    'Temporarily out of stock'
                ],
                'blocked_patterns': [
                    'sorry',
                    'robot check',
                    '503 Service Unavailable',
                    'Something went wrong',
                    'access denied'
                ]
            }
        }

    def load_selectors_from_db(self):
        """DBì—ì„œ Amazonìš© ì„ íƒì ë¡œë“œ"""
        if not self.db_engine:
            logger.warning("DB ì—°ê²°ì´ ì—†ì–´ ì„ íƒì ë¡œë“œ ë¶ˆê°€")
            return

        try:
            # Full XPathëŠ” ì œì™¸í•˜ê³  ë¡œë“œ
            query = """
            SELECT element_type, selector_value, priority
            FROM amazon_selectors
            WHERE country_code = %s
              AND is_active = TRUE
              AND selector_value NOT LIKE '/html/%'
            ORDER BY element_type, priority ASC
            """

            df = pd.read_sql(query, self.db_engine, params=(self.country_code,))
            logger.info(f"âœ… DBì—ì„œ ì„ íƒì ë¡œë“œ ì‹œì‘: {len(df)}ê°œ")

            # DBì—ì„œ ë¡œë“œí•œ ì„ íƒìë¡œ ë®ì–´ì“°ê¸°
            db_selectors = {self.country_code: {}}

            for element_type in df['element_type'].unique():
                db_selectors[self.country_code][element_type] = df[df['element_type'] == element_type]['selector_value'].tolist()
                logger.info(f"  - {element_type}: {len(db_selectors[self.country_code][element_type])}ê°œ")

            # ê¸°ë³¸ê°’ê³¼ ë³‘í•© (DB ìš°ì„ )
            for element_type, selectors in db_selectors[self.country_code].items():
                if element_type in self.selectors[self.country_code]:
                    # DB ì„ íƒìë¥¼ ì•ì— ì¶”ê°€ (ìš°ì„ ìˆœìœ„)
                    existing = self.selectors[self.country_code][element_type]
                    self.selectors[self.country_code][element_type] = selectors + [s for s in existing if s not in selectors]
                else:
                    self.selectors[self.country_code][element_type] = selectors

            logger.info(f"âœ… DB ì„ íƒì ë¡œë“œ ì™„ë£Œ")

        except Exception as e:
            logger.error(f"âŒ DB ì„ íƒì ë¡œë“œ ì‹¤íŒ¨: {e}")

    def setup_driver(self):
        """Chrome ë“œë¼ì´ë²„ ì„¤ì •"""
        logger.info("ğŸ”§ Chrome ë“œë¼ì´ë²„ ì„¤ì • ì¤‘...")

        try:
            options = uc.ChromeOptions()

            # ê¸°ë³¸ ì˜µì…˜ë“¤
            options.add_argument('--disable-blink-features=AutomationControlled')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-setuid-sandbox')

            # User-Agent ì„¤ì •
            user_agents = [
                'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
                'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            ]
            options.add_argument(f'--user-agent={random.choice(user_agents)}')

            # ì¼ë³¸ì–´ ì„¤ì •
            options.add_experimental_option('prefs', {'intl.accept_languages': 'ja-JP,ja'})

            # Chrome ë“œë¼ì´ë²„ ìƒì„±
            self.driver = uc.Chrome(options=options)
            self.driver.maximize_window()

            # WebDriverWait ê°ì²´ ìƒì„±
            self.wait = WebDriverWait(self.driver, 20)

            logger.info("âœ… ë“œë¼ì´ë²„ ì„¤ì • ì™„ë£Œ")
            return True

        except Exception as e:
            logger.error(f"âŒ ë“œë¼ì´ë²„ ì„¤ì • ì‹¤íŒ¨: {e}")
            return False

    def handle_captcha_or_block_page(self, target_url=None):
        """ì°¨ë‹¨ í˜ì´ì§€ë‚˜ ìº¡ì°¨ ì²˜ë¦¬ - Continue shopping ë²„íŠ¼ í´ë¦­ í›„ ì›ë˜ URLë¡œ ì´ë™"""
        try:
            logger.info("ğŸ” ì°¨ë‹¨/ìº¡ì°¨ í˜ì´ì§€ í™•ì¸ ì¤‘...")

            # ì¼ë³¸ ì•„ë§ˆì¡´ ì „ìš© ì„ íƒìë¥¼ ìš°ì„ ìœ¼ë¡œ ë°°ì¹˜ (ì‹¤ì œ XPath ìµœìš°ì„ )
            continue_selectors = [
                # ì‹¤ì œ ì¼ë³¸ ì•„ë§ˆì¡´ "ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã‚’ç¶šã‘ã‚‹" ë²„íŠ¼ XPath (ìµœìš°ì„ )
                "/html/body/center/center/p/table/tbody/tr/td/p[5]/a/img",
                "/html/body/center/center/p/table/tbody/tr/td/p[5]/a",
                "//table//p[5]//a//img",
                "//table//p[5]//a",

                # ê¸°ì¡´ ì¼ë³¸ ì•„ë§ˆì¡´ ì„ íƒìë“¤
                "//input[@alt='ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã‚’ç¶šã‘ã‚‹']",
                "//button[contains(text(), 'ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã‚’ç¶šã‘ã‚‹')]",
                "//a[contains(text(), 'ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã‚’ç¶šã‘ã‚‹')]",
                "//span[contains(text(), 'ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã‚’ç¶šã‘ã‚‹')]/ancestor::button",
                "//span[contains(text(), 'ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã‚’ç¶šã‘ã‚‹')]/ancestor::a",
                "input[alt*='ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã‚’ç¶šã‘ã‚‹']",
                "input[value*='ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã‚’ç¶šã‘ã‚‹']",

                # ê¸°ì¡´ ì˜ì–´ ì„ íƒìë“¤
                "//button[contains(text(), 'Continue shopping')]",
                "//button[contains(@class, 'a-button-primary')]",
                "//input[@type='submit' and contains(@value, 'Continue')]",
                "//a[contains(text(), 'Continue shopping')]",
                "//span[contains(text(), 'Continue shopping')]/ancestor::button",
                "button.a-button-primary",
                "button[type='submit']",
                "#a-autoid-0",
                ".a-button-inner"
            ]

            button_clicked = False

            for selector in continue_selectors:
                try:
                    logger.debug(f"  ì‹œë„ ì¤‘: {selector}")

                    if selector.startswith('//'):
                        # XPath
                        elements = self.driver.find_elements(By.XPATH, selector)
                        selector_type = "XPath"
                    elif selector.startswith('#') or selector.startswith('.') or '[' in selector:
                        # CSS Selector
                        elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                        selector_type = "CSS"
                    else:
                        # CSS Selector (default)
                        elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                        selector_type = "CSS"

                    logger.debug(f"      íƒ€ì…: {selector_type}, ë°œê²¬: {len(elements)}ê°œ")

                    if elements:
                        for element in elements:
                            try:
                                if element.is_displayed() and element.is_enabled():
                                    logger.info(f"âœ… Continue ë²„íŠ¼ ë°œê²¬: {selector}")

                                    # ìŠ¤í¬ë¡¤í•´ì„œ ë²„íŠ¼ì´ ë³´ì´ë„ë¡
                                    self.driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", element)
                                    time.sleep(1)

                                    # í´ë¦­ ì‹œë„ (ì—¬ëŸ¬ ë°©ë²•)
                                    try:
                                        element.click()
                                        logger.info("âœ… ì¼ë°˜ í´ë¦­ ì„±ê³µ")
                                        button_clicked = True
                                    except:
                                        try:
                                            # JavaScript í´ë¦­
                                            self.driver.execute_script("arguments[0].click();", element)
                                            logger.info("âœ… JavaScript í´ë¦­ ì„±ê³µ")
                                            button_clicked = True
                                        except:
                                            # ActionChains í´ë¦­
                                            from selenium.webdriver.common.action_chains import ActionChains
                                            ActionChains(self.driver).move_to_element(element).click().perform()
                                            logger.info("âœ… ActionChains í´ë¦­ ì„±ê³µ")
                                            button_clicked = True

                                    if button_clicked:
                                        break

                            except Exception as e:
                                logger.debug(f"      ìš”ì†Œ í´ë¦­ ì˜¤ë¥˜: {e}")
                                continue

                        if button_clicked:
                            break

                except Exception as e:
                    logger.debug(f"      ì„ íƒì ì˜¤ë¥˜: {str(e)}")
                    continue

            if not button_clicked:
                # ëª¨ë“  ë²„íŠ¼/ë§í¬ë¥¼ ê²€ì‚¬í•´ì„œ ê´€ë ¨ í…ìŠ¤íŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸
                try:
                    clickable_elements = self.driver.find_elements(By.TAG_NAME, "button") + \
                                       self.driver.find_elements(By.TAG_NAME, "input") + \
                                       self.driver.find_elements(By.TAG_NAME, "a")

                    continue_keywords = ['continue', 'shopping', 'ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°', 'ç¶šã‘ã‚‹', 'ç¶™ç¶š']

                    for element in clickable_elements:
                        try:
                            if not element.is_displayed() or not element.is_enabled():
                                continue

                            # í…ìŠ¤íŠ¸, alt, value ì†ì„± í™•ì¸
                            element_text = (element.text or '').lower()
                            element_alt = (element.get_attribute('alt') or '').lower()
                            element_value = (element.get_attribute('value') or '').lower()

                            all_text = f"{element_text} {element_alt} {element_value}"

                            if any(keyword in all_text for keyword in continue_keywords):
                                logger.info(f"âœ… ë²„íŠ¼ ë°œê²¬ (í…ìŠ¤íŠ¸ ë§¤ì¹­): '{element.text or element_alt or element_value}'")

                                # ìŠ¤í¬ë¡¤í•´ì„œ ë²„íŠ¼ì´ ë³´ì´ë„ë¡
                                self.driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", element)
                                time.sleep(1)

                                try:
                                    element.click()
                                    button_clicked = True
                                    logger.info("âœ… í…ìŠ¤íŠ¸ ë§¤ì¹­ ë²„íŠ¼ í´ë¦­ ì„±ê³µ")
                                    break
                                except:
                                    try:
                                        self.driver.execute_script("arguments[0].click();", element)
                                        button_clicked = True
                                        logger.info("âœ… í…ìŠ¤íŠ¸ ë§¤ì¹­ JavaScript í´ë¦­ ì„±ê³µ")
                                        break
                                    except:
                                        continue

                        except Exception:
                            continue

                except Exception as e:
                    logger.debug(f"ì „ì²´ ë²„íŠ¼ ê²€ì‚¬ ì˜¤ë¥˜: {e}")

            if button_clicked:
                logger.info("ğŸ”„ Continue ë²„íŠ¼ í´ë¦­ ì™„ë£Œ, í˜ì´ì§€ ë¡œë”© ëŒ€ê¸° ì¤‘...")
                time.sleep(5)  # í˜ì´ì§€ ì „í™˜ ëŒ€ê¸°

                # ì›ë˜ URLë¡œ ì´ë™ (target_urlì´ ì œê³µëœ ê²½ìš°)
                if target_url:
                    logger.info(f"ğŸ¯ ì›ë˜ URLë¡œ ì´ë™: {target_url}")
                    self.driver.get(target_url)
                    time.sleep(3)
                    self.wait_for_page_load()

                return True
            else:
                logger.debug("Continue ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return False

        except Exception as e:
            logger.error(f"ì°¨ë‹¨ í˜ì´ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    def is_page_blocked(self):
        """í˜ì´ì§€ ì°¨ë‹¨ ê°ì§€"""
        try:
            page_title = self.driver.title.lower()
            page_source = self.driver.page_source.lower()
            current_url = self.driver.current_url.lower()

            # ì¼ë³¸ ì•„ë§ˆì¡´ ì°¨ë‹¨ í˜ì´ì§€ íŠ¹ì§•
            japanese_block_indicators = [
                'ã”è¿·æƒ‘ã‚’ãŠã‹ã‘ã—ã¦ã„ã¾ã™',  # "ã”è¿·æƒ‘ã‚’ãŠã‹ã‘ã—ã¦ã„ã¾ã™"
                'ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã‚’ç¶šã‘ã‚‹',      # "ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã‚’ç¶šã‘ã‚‹"
                'ãŠå®¢æ§˜ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ',
                'ã—ã°ã‚‰ãã—ã¦ã‹ã‚‰',
                'amazon.co.jpãƒ›ãƒ¼ãƒ ã¸'
            ]

            # ì¼ë³¸ì–´ ì°¨ë‹¨ í˜ì´ì§€ í™•ì¸
            for indicator in japanese_block_indicators:
                if indicator in page_source:
                    logger.warning(f"ğŸš« ì¼ë³¸ ì•„ë§ˆì¡´ ì°¨ë‹¨ í˜ì´ì§€ ê°ì§€: '{indicator}'")
                    return True

            # ê¸°ì¡´ ì˜ì–´ ì°¨ë‹¨ ì§•í›„ë“¤
            serious_blocked_indicators = {
                'title': [
                    '503',
                    'access denied',
                    'error has occurred',
                    'sorry'
                ],
                'content': [
                    'enter the characters',
                    'verify you are human',
                    'access denied',
                    'automated access',
                    'suspicious activity',
                    'robot check'
                ]
            }

            # ì œëª© í™•ì¸
            for pattern in serious_blocked_indicators['title']:
                if pattern in page_title:
                    logger.warning(f"ğŸš« ì°¨ë‹¨ ê°ì§€ (ì œëª©): '{pattern}' in '{page_title}'")
                    return True

            # Continue shoppingì´ ìˆìœ¼ë©´ ì°¨ë‹¨ í˜ì´ì§€ë¡œ ê°„ì£¼
            if 'continue shopping' in page_source or 'ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã‚’ç¶šã‘ã‚‹' in page_source:
                logger.warning("ğŸš« Continue shopping í˜ì´ì§€ ê°ì§€")
                return True

            # ë³¸ë¬¸ í™•ì¸
            for pattern in serious_blocked_indicators['content']:
                if pattern in page_source:
                    logger.warning(f"ğŸš« ì°¨ë‹¨ ê°ì§€ (ë³¸ë¬¸): '{pattern}'")

                    # ìŠ¤í¬ë¦°ìƒ· ì €ì¥
                    try:
                        local_time = datetime.now(self.local_tz)
                        screenshot_name = f"blocked_{self.country_code}_{local_time.strftime('%Y%m%d_%H%M%S')}.png"
                        self.driver.save_screenshot(screenshot_name)
                        logger.info(f"ğŸ“¸ ì°¨ë‹¨ í˜ì´ì§€ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {screenshot_name}")
                    except:
                        pass

                    return True

            # Amazon í˜ì´ì§€ê°€ ì•„ë‹Œ ê²½ìš°
            if 'amazon' not in current_url:
                logger.warning(f"ğŸš« Amazon í˜ì´ì§€ê°€ ì•„ë‹˜: {current_url}")
                return True

            return False

        except Exception as e:
            logger.error(f"í˜ì´ì§€ ì°¨ë‹¨ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    def wait_for_page_load(self, timeout=10):
        """í˜ì´ì§€ ë¡œë“œ ëŒ€ê¸°"""
        try:
            # JavaScript ì‹¤í–‰ ì™„ë£Œ ëŒ€ê¸°
            self.wait.until(
                lambda driver: driver.execute_script("return document.readyState") == "complete"
            )

            # ì¶”ê°€ë¡œ Amazon íŠ¹ì • ìš”ì†Œ ëŒ€ê¸°
            possible_elements = [
                (By.ID, "productTitle"),
                (By.ID, "priceblock_ourprice"),
                (By.CLASS_NAME, "a-price-whole"),
                (By.ID, "availability"),
                (By.ID, "imageBlock")
            ]

            for by, value in possible_elements:
                try:
                    WebDriverWait(self.driver, 3).until(
                        EC.presence_of_element_located((by, value))
                    )
                    logger.debug(f"âœ… ìš”ì†Œ ë°œê²¬: {by}={value}")
                    return True
                except:
                    continue

            return True

        except Exception as e:
            logger.warning(f"í˜ì´ì§€ ë¡œë“œ ëŒ€ê¸° ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    def extract_element_text(self, selectors, element_name="ìš”ì†Œ"):
        """ì„ íƒì ëª©ë¡ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        logger.debug(f"ğŸ” {element_name} ì¶”ì¶œ ì‹œì‘ - ì´ {len(selectors)}ê°œ ì„ íƒì")

        for idx, selector in enumerate(selectors, 1):
            try:
                logger.debug(f"  [{idx}/{len(selectors)}] ì‹œë„ ì¤‘: {selector}")

                # XPathì¸ì§€ CSS ì„ íƒìì¸ì§€ êµ¬ë¶„
                if selector.startswith('//') or selector.startswith('('):
                    # XPath
                    elements = self.driver.find_elements(By.XPATH, selector)
                    selector_type = "XPath"
                else:
                    # CSS Selector
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    selector_type = "CSS"

                logger.debug(f"      íƒ€ì…: {selector_type}, ë°œê²¬: {len(elements)}ê°œ")

                if elements:
                    for i, element in enumerate(elements):
                        try:
                            if element.is_displayed():
                                # ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                                text1 = element.text.strip()
                                text2 = element.get_attribute('textContent').strip() if element.get_attribute('textContent') else ""
                                text3 = element.get_attribute('innerText').strip() if element.get_attribute('innerText') else ""

                                # ê°€ì¥ ê¸´ í…ìŠ¤íŠ¸ ì„ íƒ
                                text = max([text1, text2, text3], key=len)

                                if text:
                                    logger.debug(f"      âœ… ì¶”ì¶œ ì„±ê³µ: '{text[:100]}'")
                                    return text
                        except Exception as e:
                            logger.debug(f"      ìš”ì†Œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

            except Exception as e:
                logger.debug(f"      âŒ ì„ íƒì ì˜¤ë¥˜: {str(e)}")
                continue

        logger.debug(f"âŒ {element_name} ì¶”ì¶œ ì‹¤íŒ¨")
        return None

    def extract_price(self, country_code):
        """ê°€ê²© ì¶”ì¶œ (ì¶”ì²œ ìƒí’ˆ ì˜ì—­ ì™„ì „ ì œì™¸)"""
        logger.info(f"ğŸ’° ê°€ê²© ì¶”ì¶œ ì‹œì‘ - êµ­ê°€: {country_code}")

        # ì¶”ì²œ ìƒí’ˆ ì˜ì—­ ì œì™¸ (ì´ ì˜ì—­ë“¤ì€ ì™„ì „íˆ ë¬´ì‹œ)
        excluded_areas = [
            "#similarities_feature_div",  # ì¶”ì²œ ìƒí’ˆ
            "#sp_detail",  # ìŠ¤í°ì„œ ìƒí’ˆ
            "#bookDescription_feature_div",  # ë„ì„œ ì„¤ëª…
            "#books-entity-details",  # ë„ì„œ ìƒì„¸
            "#compare-table",  # ë¹„êµ í…Œì´ë¸”
            "[data-cel-widget*='comparison']",  # ë¹„êµ ìœ„ì ¯
            "[data-cel-widget*='sponsored']",  # ìŠ¤í°ì„œ
            ".s-result-item",  # ê²€ìƒ‰ ê²°ê³¼ ì•„ì´í…œ
            ".a-carousel-card",  # ì¹´ë£¨ì…€ ì¹´ë“œ
            ".acs-shwcs-widget",  # ì¶”ì²œ ìœ„ì ¯
            "#customer_also_viewed_feature_div",  # ê³ ê°ì´ ë³¸ ìƒí’ˆ
            "#similarities-widget",  # ìœ ì‚¬ ìƒí’ˆ
            ".a-accordion-inner"  # ì•„ì½”ë””ì–¸ ë‚´ë¶€
        ]

        # ë©”ì¸ ì œí’ˆ ì˜ì—­ë§Œ í™•ì¸
        main_product_areas = [
            "#dp-container",  # ë©”ì¸ ì œí’ˆ ì»¨í…Œì´ë„ˆ
            "#centerCol",     # ì¤‘ì•™ ì»¬ëŸ¼
            "#rightCol",      # ìš°ì¸¡ ì»¬ëŸ¼ (êµ¬ë§¤ ë°•ìŠ¤)
            "#apex_desktop"   # ë°ìŠ¤í¬í†± ë©”ì¸ ì˜ì—­
        ]

        price_selectors = self.selectors[country_code].get('price', [])

        for idx, selector in enumerate(price_selectors, 1):
            try:
                logger.debug(f"  [{idx}/{len(price_selectors)}] ê°€ê²© ì„ íƒì ì‹œë„: {selector}")

                # ìš”ì†Œ ì°¾ê¸°
                if selector.startswith('//'):
                    elements = self.driver.find_elements(By.XPATH, selector)
                    selector_type = "XPath"
                else:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    selector_type = "CSS"

                logger.debug(f"      íƒ€ì…: {selector_type}, ë°œê²¬: {len(elements)}ê°œ")

                for i, element in enumerate(elements):
                    try:
                        if not element.is_displayed():
                            continue

                        # ì¶”ì²œ ìƒí’ˆ ì˜ì—­ì— ìˆëŠ”ì§€ í™•ì¸ (ì œì™¸)
                        is_in_excluded_area = False

                        for excluded_selector in excluded_areas:
                            try:
                                if excluded_selector.startswith('['):
                                    # ì†ì„± ì„ íƒì
                                    excluded_elements = self.driver.find_elements(By.CSS_SELECTOR, excluded_selector)
                                else:
                                    # IDë‚˜ í´ë˜ìŠ¤ ì„ íƒì
                                    excluded_elements = self.driver.find_elements(By.CSS_SELECTOR, excluded_selector)

                                for excluded_area in excluded_elements:
                                    if self.driver.execute_script(
                                        "return arguments[0].contains(arguments[1]);",
                                        excluded_area, element
                                    ):
                                        is_in_excluded_area = True
                                        break

                                if is_in_excluded_area:
                                    break
                            except:
                                continue

                        if is_in_excluded_area:
                            continue

                        # ë©”ì¸ ì œí’ˆ ì˜ì—­ì— ìˆëŠ”ì§€ í™•ì¸ (í¬í•¨)
                        is_in_main_area = False

                        for main_selector in main_product_areas:
                            try:
                                main_area = self.driver.find_element(By.CSS_SELECTOR, main_selector)
                                if self.driver.execute_script(
                                    "return arguments[0].contains(arguments[1]);",
                                    main_area, element
                                ):
                                    is_in_main_area = True
                                    break
                            except:
                                continue

                        # ë©”ì¸ ì˜ì—­ì—ë„ ì—†ê³  ê°€ê²© í´ë˜ìŠ¤ë„ ì•„ë‹ˆë©´ ì œì™¸
                        if not is_in_main_area:
                            element_class = element.get_attribute('class') or ''
                            if 'a-price' in element_class:
                                is_in_main_area = True
                            else:
                                continue

                        # í…ìŠ¤íŠ¸ ì¶”ì¶œ
                        text1 = element.text.strip()
                        text2 = element.get_attribute('textContent').strip() if element.get_attribute('textContent') else ""
                        text3 = element.get_attribute('innerText').strip() if element.get_attribute('innerText') else ""

                        price_text = max([text1, text2, text3], key=len)

                        if price_text:
                            # êµ­ê°€ë³„ ê°€ê²© íŒŒì‹±
                            price = self.parse_price_by_country(price_text, country_code)
                            if price and price > 0:  # 0ë³´ë‹¤ í° ê°’ë§Œ ë°˜í™˜
                                logger.info(f"âœ… ê°€ê²© ì¶”ì¶œ ì„±ê³µ: {price} (ì›ë³¸: {price_text})")
                                return price

                    except Exception as e:
                        logger.debug(f"ìš”ì†Œ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

            except Exception as e:
                logger.debug(f"ì„ íƒì ì˜¤ë¥˜: {str(e)}")

        # JavaScriptë¡œ ë©”ì¸ ì˜ì—­ì—ì„œë§Œ ê°€ê²© ì°¾ê¸°
        logger.debug("JavaScriptë¡œ ë©”ì¸ ì˜ì—­ ê°€ê²© ê²€ìƒ‰...")
        try:
            js_result = self.driver.execute_script("""
                // ë©”ì¸ ì œí’ˆ ì˜ì—­ë§Œ ê²€ìƒ‰
                const mainAreas = [
                    '#dp-container',
                    '#centerCol',
                    '#rightCol',
                    '#apex_desktop'
                ];

                // ì œì™¸í•  ì˜ì—­ë“¤
                const excludedAreas = [
                    '#similarities_feature_div',
                    '#sp_detail',
                    '.s-result-item',
                    '.a-carousel-card',
                    '.acs-shwcs-widget',
                    '#customer_also_viewed_feature_div',
                    '[data-cel-widget*="comparison"]',
                    '[data-cel-widget*="sponsored"]'
                ];

                const results = [];

                // ë©”ì¸ ì˜ì—­ì—ì„œ ê²€ìƒ‰
                for (let mainSelector of mainAreas) {
                    const mainArea = document.querySelector(mainSelector);
                    if (mainArea) {
                        const priceElements = mainArea.querySelectorAll('span, div');

                        for (let elem of priceElements) {
                            // ì œì™¸ ì˜ì—­ì— ìˆëŠ”ì§€ í™•ì¸
                            let isExcluded = false;
                            for (let excludedSelector of excludedAreas) {
                                const excludedArea = document.querySelector(excludedSelector);
                                if (excludedArea && excludedArea.contains(elem)) {
                                    isExcluded = true;
                                    break;
                                }
                            }

                            if (isExcluded) continue;

                            const text = elem.textContent.trim();
                            // ì¼ë³¸ ì—”í™” ë° ê¸°íƒ€ ê°€ê²© íŒ¨í„´ ë§¤ì¹­
                            if (text.match(/[Â¥ï¿¥][\d,]+/) || text.match(/[$Â£â‚¬â‚¹][\d,]+\.?\d*/) || text.match(/\d+[.,]\d{2}$/)) {
                                if (text.length < 20 && text.length > 1) {
                                    results.push({
                                        text: text,
                                        tag: elem.tagName,
                                        class: elem.className,
                                        id: elem.id,
                                        area: mainSelector
                                    });
                                }
                            }
                        }
                    }
                }

                return results.slice(0, 3);  // ìƒìœ„ 3ê°œë§Œ
            """)

            if js_result:
                for r in js_result:
                    price = self.parse_price_by_country(r['text'], country_code)
                    if price and price > 0:  # 0ë³´ë‹¤ í° ê°’ë§Œ ë°˜í™˜
                        logger.info(f"âœ… JavaScript ê°€ê²© ì¶”ì¶œ ì„±ê³µ: {price}")
                        return price

        except Exception as e:
            logger.debug(f"JavaScript ê°€ê²© ì¶”ì¶œ ì‹¤íŒ¨: {e}")

        logger.warning("âŒ ë©”ì¸ ì˜ì—­ì—ì„œ ê°€ê²©ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        return None

    def parse_price_by_country(self, price_text, country_code):
        """êµ­ê°€ë³„ ê°€ê²© íŒŒì‹±"""
        try:
            # ê¸°ë³¸ ì •ë¦¬
            price_text = price_text.strip()

            if country_code == 'jp':
                # ì¼ë³¸: Â¥1,234 í˜•ì‹
                price_text = re.sub(r'[Â¥ï¿¥\s]', '', price_text)
                price_text = price_text.replace(',', '')
                match = re.search(r'(\d+)', price_text)
                if match:
                    result = float(match.group(1))
                    return result if result > 0 else None

            elif country_code in ['fr', 'it', 'es', 'de']:
                # ìœ ëŸ½: 1.234,56 í˜•ì‹
                price_text = re.sub(r'[â‚¬\s]', '', price_text)
                price_text = price_text.replace('.', '')
                price_text = price_text.replace(',', '.')
                match = re.search(r'(\d+\.?\d*)', price_text)
                if match:
                    result = float(match.group(1))
                    return result if result > 0 else None

            elif country_code == 'in':
                # ì¸ë„: â‚¹1,234.56 í˜•ì‹
                price_text = re.sub(r'[â‚¹\s]', '', price_text)
                price_text = price_text.replace(',', '')
                match = re.search(r'(\d+\.?\d*)', price_text)
                if match:
                    result = float(match.group(1))
                    return result if result > 0 else None

            else:
                # ì˜ë¯¸ê¶Œ: $1,234.56 í˜•ì‹
                price_text = re.sub(r'[$Â£\s]', '', price_text)
                price_text = price_text.replace(',', '')
                match = re.search(r'(\d+\.?\d*)', price_text)
                if match:
                    result = float(match.group(1))
                    return result if result > 0 else None

        except Exception as e:
            logger.debug(f"ê°€ê²© íŒŒì‹± ì˜¤ë¥˜: {price_text} - {e}")

        return None

    def validate_seller_info(self, ships_from, sold_by):
        """ships_fromê³¼ sold_by ì •ë³´ ê²€ì¦ - ë‘˜ ë‹¤ ë¹„ì–´ìˆì„ ë•Œë§Œ False"""
        try:
            # ê°„ë‹¨í•œ ë¹„ì–´ìˆìŒ ì²´í¬
            ships_from_exists = ships_from and str(ships_from).strip()
            sold_by_exists = sold_by and str(sold_by).strip()

            logger.info(f"ğŸ” íŒë§¤ì ì •ë³´ í™•ì¸: ships_from='{ships_from}', sold_by='{sold_by}'")
            logger.info(f"   ships_from ì¡´ì¬: {ships_from_exists}, sold_by ì¡´ì¬: {sold_by_exists}")

            # ë‘˜ ë‹¤ ë¹„ì–´ìˆìœ¼ë©´ False
            if not ships_from_exists and not sold_by_exists:
                logger.warning("âš ï¸ ships_fromê³¼ sold_by ëª¨ë‘ ë¹„ì–´ìˆìŒ - ê°€ê²© 0 ì„¤ì •")
                return False

            logger.info("âœ… íŒë§¤ì ì •ë³´ ìˆìŒ - ì •ìƒ ê°€ê²© ì¶”ì¶œ ì§„í–‰")
            return True

        except Exception as e:
            logger.error(f"íŒë§¤ì ì •ë³´ ê²€ì¦ ì˜¤ë¥˜: {e}")
            return True  # ì˜¤ë¥˜ì‹œ ì •ìƒ ì²˜ë¦¬

    def extract_product_info(self, url, row_data, retry_count=0, max_retries=3):
        """ì œí’ˆ ì •ë³´ ì¶”ì¶œ - ì°¨ë‹¨ í˜ì´ì§€ ì²˜ë¦¬ ê°œì„  (V2: íƒ€ì„ì¡´ ë¶„ë¦¬)"""
        try:
            logger.info(f"\n{'='*60}")
            logger.info(f"ğŸ” ì œí’ˆ ì •ë³´ ì¶”ì¶œ ì‹œì‘")
            logger.info(f"ğŸ“Œ URL: {url}")
            logger.info(f"ğŸ“Œ ë¸Œëœë“œ: {row_data.get('brand', 'N/A')}")
            logger.info(f"ğŸ“Œ ì œí’ˆ: {row_data.get('item', 'N/A')}")

            # í˜ì´ì§€ ë¡œë“œ
            self.driver.get(url)
            time.sleep(random.uniform(2, 4))

            # ì°¨ë‹¨ í˜ì´ì§€ í™•ì¸ ë° ì²˜ë¦¬
            if self.is_page_blocked():
                logger.warning("âš ï¸ ì°¨ë‹¨ í˜ì´ì§€ ê°ì§€ë¨")

                # Continue shopping ë²„íŠ¼ í´ë¦­í•˜ê³  ì›ë˜ URLë¡œ ì¬ì‹œë„
                if self.handle_captcha_or_block_page(target_url=url):
                    logger.info("âœ… ì°¨ë‹¨ í˜ì´ì§€ ì²˜ë¦¬ ì™„ë£Œ, í˜ì´ì§€ ì¬ë¡œë“œë¨")
                    time.sleep(3)

                    # ì—¬ì „íˆ ì°¨ë‹¨ í˜ì´ì§€ì¸ì§€ ì¬í™•ì¸
                    if self.is_page_blocked():
                        logger.error("âŒ ì—¬ì „íˆ ì°¨ë‹¨ í˜ì´ì§€ì„")
                        raise Exception("í˜ì´ì§€ ì°¨ë‹¨ ì§€ì†")
                else:
                    logger.error("âŒ ì°¨ë‹¨ í˜ì´ì§€ ì²˜ë¦¬ ì‹¤íŒ¨")
                    raise Exception("ì°¨ë‹¨ í˜ì´ì§€ ì²˜ë¦¬ ì‹¤íŒ¨")

            # í˜ì´ì§€ ë¡œë“œ ëŒ€ê¸°
            self.wait_for_page_load()

            # V2: íƒ€ì„ì¡´ ë¶„ë¦¬ - ì¼ë³¸ ì‹œê°„ + í•œêµ­ ì‹œê°„
            local_time = datetime.now(self.local_tz)
            korea_time = datetime.now(self.korea_tz)

            # ê¸°ë³¸ ê²°ê³¼ êµ¬ì¡°
            result = {
                'retailerid': row_data.get('retailerid', ''),
                'country_code': self.country_code,
                'ships_from': None,
                'channel': row_data.get('channel', 'Online'),
                'retailersku': row_data.get('retailersku', ''),
                'brand': row_data.get('brand', ''),
                'brand_eng': row_data.get('brand_eng', row_data.get('brand', '')),
                'form_factor': row_data.get('form_factor', ''),
                'segment_lv1': row_data.get('seg_lv1', ''),
                'segment_lv2': row_data.get('seg_lv2', ''),
                'segment_lv3': row_data.get('seg_lv3', ''),
                'capacity': row_data.get('capacity', ''),
                'item': row_data.get('item', ''),
                # V2: 4ê°œì˜ íƒ€ì„ìŠ¤íƒ¬í”„ (í˜„ì§€ + í•œêµ­)
                'crawl_datetime': local_time.strftime('%Y-%m-%d %H:%M'),
                'crawl_strdatetime': local_time.strftime('%Y%m%d%H%M%S') + f"{local_time.microsecond:06d}"[:4],
                'kr_crawl_datetime': korea_time.strftime('%Y-%m-%d %H:%M'),
                'kr_crawl_strdatetime': korea_time.strftime('%Y%m%d%H%M%S') + f"{korea_time.microsecond:06d}"[:4],
                'retailprice': None,
                'sold_by': None,
                'imageurl': None,
                'producturl': url,
                'title': None,
                'vat': row_data.get('vat', 'o')
            }

            # ì œëª© ì¶”ì¶œ
            result['title'] = self.extract_element_text(
                self.selectors[self.country_code].get('title', []),
                "ì œëª©"
            )

            # íŒë§¤ì ì •ë³´ ì¶”ì¶œ
            result['sold_by'] = self.extract_element_text(
                self.selectors[self.country_code].get('sold_by', []),
                "íŒë§¤ì"
            )

            # ë°°ì†¡ì§€ ì •ë³´ ì¶”ì¶œ
            result['ships_from'] = self.extract_element_text(
                self.selectors[self.country_code].get('ships_from', []),
                "ë°°ì†¡ì§€"
            )

            # íŒë§¤ì ì •ë³´ ê²€ì¦ í›„ ê°€ê²© ê²°ì •
            seller_info_valid = self.validate_seller_info(result['ships_from'], result['sold_by'])

            if not seller_info_valid:
                # ships_fromê³¼ sold_by ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ê°€ê²© 0
                result['retailprice'] = None
                logger.info("ğŸ’° ìµœì¢… ê°€ê²©: None (ì´ìœ : íŒë§¤ì ì •ë³´ ì—†ìŒ)")
            else:
                # í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ê¸°ì¡´ ê°€ê²© ì¶”ì¶œ ë¡œì§ ì‚¬ìš©
                logger.info("ğŸ’° ê°€ê²© ì¶”ì¶œ ì‹œì‘ (íŒë§¤ì ì •ë³´ ìˆìŒ)")
                result['retailprice'] = self.extract_price(self.country_code)

                if result['retailprice'] is not None:
                    logger.info(f"ğŸ’° ìµœì¢… ê°€ê²©: {result['retailprice']} (ì •ìƒ ì¶”ì¶œ)")
                else:
                    logger.warning("ğŸ’° ìµœì¢… ê°€ê²©: None (ì¶”ì¶œ ì‹¤íŒ¨)")

            # ì´ë¯¸ì§€ URL ì¶”ì¶œ
            for selector in self.selectors[self.country_code].get('imageurl', []):
                try:
                    if selector.startswith('//'):
                        element = self.driver.find_element(By.XPATH, selector)
                    else:
                        element = self.driver.find_element(By.CSS_SELECTOR, selector)

                    result['imageurl'] = element.get_attribute('src')
                    if result['imageurl']:
                        logger.debug(f"âœ… ì´ë¯¸ì§€ URL ì¶”ì¶œ ì„±ê³µ")
                        break
                except:
                    continue

            # ê²°ê³¼ ìš”ì•½
            logger.info(f"\nğŸ“Š ì¶”ì¶œ ê²°ê³¼:")
            logger.info(f"   ğŸ“Œ ì œëª©: {result['title'][:50] + '...' if result['title'] and len(result['title']) > 50 else result['title']}")
            logger.info(f"   ğŸ’° ê°€ê²©: {result['retailprice']}")
            logger.info(f"   ğŸ–¼ï¸ ì´ë¯¸ì§€: {'ìˆìŒ' if result['imageurl'] else 'ì—†ìŒ'}")
            logger.info(f"   ğŸª íŒë§¤ì: {result['sold_by']}")
            logger.info(f"   ğŸ“¦ ë°°ì†¡ì§€: {result['ships_from']}")
            logger.info(f"   â° ì¼ë³¸ ì‹œê°„: {result['crawl_datetime']}")
            logger.info(f"   â° í•œêµ­ ì‹œê°„: {result['kr_crawl_datetime']}")

            return result

        except Exception as e:
            logger.error(f"âŒ í˜ì´ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

            if retry_count < max_retries:
                wait_time = (retry_count + 1) * 10
                logger.info(f"ğŸ”„ {wait_time}ì´ˆ í›„ ì¬ì‹œë„... ({retry_count + 1}/{max_retries})")
                time.sleep(wait_time)

                # ë“œë¼ì´ë²„ ì¬ì‹œì‘
                try:
                    self.driver.refresh()
                except:
                    logger.info("ğŸ”§ ë“œë¼ì´ë²„ ì¬ì‹œì‘ ì¤‘...")
                    self.driver.quit()
                    self.setup_driver()

                return self.extract_product_info(url, row_data, retry_count + 1, max_retries)

            # ìµœì¢… ì‹¤íŒ¨ - ê¸°ë³¸ê°’ ë°˜í™˜
            local_time = datetime.now(self.local_tz)
            korea_time = datetime.now(self.korea_tz)

            return {
                'retailerid': row_data.get('retailerid', ''),
                'country_code': self.country_code,
                'ships_from': None,
                'channel': row_data.get('channel', 'Online'),
                'retailersku': row_data.get('retailersku', ''),
                'brand': row_data.get('brand', ''),
                'brand_eng': row_data.get('brand_eng', row_data.get('brand', '')),
                'form_factor': row_data.get('form_factor', ''),
                'segment_lv1': row_data.get('seg_lv1', ''),
                'segment_lv2': row_data.get('seg_lv2', ''),
                'segment_lv3': row_data.get('seg_lv3', ''),
                'capacity': row_data.get('capacity', ''),
                'item': row_data.get('item', ''),
                'crawl_datetime': local_time.strftime('%Y-%m-%d %H:%M'),
                'crawl_strdatetime': local_time.strftime('%Y%m%d%H%M%S') + f"{local_time.microsecond:06d}"[:4],
                'kr_crawl_datetime': korea_time.strftime('%Y-%m-%d %H:%M'),
                'kr_crawl_strdatetime': korea_time.strftime('%Y%m%d%H%M%S') + f"{korea_time.microsecond:06d}"[:4],
                'retailprice': None,
                'sold_by': None,
                'imageurl': None,
                'producturl': url,
                'title': None,
                'vat': row_data.get('vat', 'o')
            }

    def get_crawl_targets(self, limit=None):
        """DBì—ì„œ í¬ë¡¤ë§ ëŒ€ìƒ URL ëª©ë¡ ì¡°íšŒ"""
        try:
            query = f"""
            SELECT *
            FROM samsung_price_tracking_list
            WHERE country = '{self.country_code}'
              AND mall_name = 'amazon'
              AND is_active = TRUE
            """

            if limit:
                query += f" LIMIT {limit}"

            df = pd.read_sql(query, self.db_engine)
            logger.info(f"âœ… í¬ë¡¤ë§ ëŒ€ìƒ {len(df)}ê°œ ì¡°íšŒ ì™„ë£Œ")
            return df.to_dict('records')

        except Exception as e:
            logger.error(f"í¬ë¡¤ë§ ëŒ€ìƒ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def save_to_db(self, df):
        """DBì— ê²°ê³¼ ì €ì¥ (V2: ìƒˆ í…Œì´ë¸”)"""
        if self.db_engine is None:
            logger.warning("âš ï¸ DB ì—°ê²°ì´ ì—†ì–´ DB ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤")
            return False

        try:
            # V2: í…Œì´ë¸”ëª… ë³€ê²½
            table_name = f'amazon_price_crawl_tbl_{self.country_code}_v2'

            # ë°ì´í„° ì €ì¥
            df.to_sql(table_name, self.db_engine, if_exists='append', index=False)
            logger.info(f"âœ… DB ì €ì¥ ì™„ë£Œ: {len(df)}ê°œ ë ˆì½”ë“œ â†’ {table_name}")

            # í¬ë¡¤ë§ ë¡œê·¸ ì €ì¥
            log_records = []
            for _, row in df.iterrows():
                log_records.append({
                    'country_code': self.country_code,
                    'url': row['producturl'],
                    'status': 'success' if row['retailprice'] is not None else 'failed',
                    'error_message': None if row['retailprice'] is not None else 'Price not found',
                    'execution_time': random.uniform(3, 10),
                    'retailprice': row['retailprice'],
                    'crawl_datetime': row['kr_crawl_datetime']  # V2: í•œêµ­ì‹œê°„ ì‚¬ìš©
                })

            if log_records:
                log_df = pd.DataFrame(log_records)
                log_df.to_sql('amazon_crawl_logs', self.db_engine, if_exists='append', index=False)
                logger.info(f"âœ… í¬ë¡¤ë§ ë¡œê·¸ ì €ì¥ ì™„ë£Œ: {len(log_records)}ê°œ")

            return True

        except Exception as e:
            logger.error(f"âŒ DB ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def upload_to_file_server(self, local_file_path, remote_filename=None, date_str=None):
        """íŒŒì¼ì„œë²„ì— ì—…ë¡œë“œ (V2: ë‚ ì§œë³„ ë””ë ‰í† ë¦¬ + ZIP ì••ì¶•)"""
        try:
            transport = paramiko.Transport((FILE_SERVER_CONFIG['host'], FILE_SERVER_CONFIG['port']))
            transport.connect(
                username=FILE_SERVER_CONFIG['username'],
                password=FILE_SERVER_CONFIG['password']
            )
            sftp = paramiko.SFTPClient.from_transport(transport)

            # êµ­ê°€ë³„ ë””ë ‰í† ë¦¬ ê²½ë¡œ
            country_dir = f"{FILE_SERVER_CONFIG['upload_path']}/{self.country_code}"

            # V2: ë‚ ì§œë³„ ë””ë ‰í† ë¦¬ ìƒì„±
            if date_str:
                date_dir = f"{country_dir}/{date_str}"

                # ë””ë ‰í† ë¦¬ ìƒì„±
                for dir_path in [country_dir, date_dir]:
                    try:
                        sftp.stat(dir_path)
                    except FileNotFoundError:
                        logger.info(f"ğŸ“ ë””ë ‰í† ë¦¬ ìƒì„±: {dir_path}")
                        sftp.mkdir(dir_path)

                # CSV íŒŒì¼ ì—…ë¡œë“œ (ë‚ ì§œë³„ ë””ë ‰í† ë¦¬)
                if remote_filename is None:
                    remote_filename = os.path.basename(local_file_path)

                remote_path = f"{date_dir}/{remote_filename}"
                sftp.put(local_file_path, remote_path)
                logger.info(f"âœ… íŒŒì¼ì„œë²„ ì—…ë¡œë“œ ì™„ë£Œ: {remote_path}")

                # V2: ZIP íŒŒì¼ ìƒì„±/ì—…ë°ì´íŠ¸
                zip_filename = f"{date_str}.zip"
                local_zip_path = f"temp_{zip_filename}"
                remote_zip_path = f"{country_dir}/{zip_filename}"

                # ê¸°ì¡´ ZIP íŒŒì¼ì´ ìˆìœ¼ë©´ ë‹¤ìš´ë¡œë“œ
                zip_exists = False
                try:
                    sftp.stat(remote_zip_path)
                    sftp.get(remote_zip_path, local_zip_path)
                    zip_exists = True
                    logger.info(f"ğŸ“¦ ê¸°ì¡´ ZIP íŒŒì¼ ë‹¤ìš´ë¡œë“œ: {remote_zip_path}")
                except FileNotFoundError:
                    logger.info(f"ğŸ“¦ ìƒˆ ZIP íŒŒì¼ ìƒì„±: {zip_filename}")

                # ZIP íŒŒì¼ì— CSV ì¶”ê°€ (temp_ ì œê±°ëœ íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥)
                with zipfile.ZipFile(local_zip_path, 'a' if zip_exists else 'w', zipfile.ZIP_DEFLATED) as zipf:
                    zipf.write(local_file_path, remote_filename)
                    logger.info(f"âœ… ZIP íŒŒì¼ì— ì¶”ê°€: {remote_filename}")

                # ZIP íŒŒì¼ ì—…ë¡œë“œ
                sftp.put(local_zip_path, remote_zip_path)
                logger.info(f"âœ… ZIP íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {remote_zip_path}")

                # ë¡œì»¬ ZIP íŒŒì¼ ì‚­ì œ
                if os.path.exists(local_zip_path):
                    os.remove(local_zip_path)

            else:
                # ë‚ ì§œ ì •ë³´ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹
                try:
                    sftp.stat(country_dir)
                except FileNotFoundError:
                    logger.info(f"ğŸ“ ë””ë ‰í† ë¦¬ ìƒì„±: {country_dir}")
                    sftp.mkdir(country_dir)

                if remote_filename is None:
                    remote_filename = os.path.basename(local_file_path)

                remote_path = f"{country_dir}/{remote_filename}"
                sftp.put(local_file_path, remote_path)
                logger.info(f"âœ… íŒŒì¼ì„œë²„ ì—…ë¡œë“œ ì™„ë£Œ: {remote_path}")

            sftp.close()
            transport.close()

            return True

        except Exception as e:
            logger.error(f"âŒ íŒŒì¼ì„œë²„ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False

    def save_results(self, df, save_db=True, upload_server=True):
        """ê²°ê³¼ë¥¼ DBì™€ íŒŒì¼ì„œë²„ì— ì €ì¥ (V2: íŒŒì¼ëª… í˜•ì‹ ë³€ê²½)"""
        # V2: ì¼ë³¸ í˜„ì§€ ì‹œê°„ ê¸°ì¤€
        local_time = datetime.now(self.local_tz)
        date_str = local_time.strftime("%Y%m%d")
        time_str = local_time.strftime("%H%M%S")
        country_code = self.country_code
        mall_name = "amazon"

        # V2: íŒŒì¼ëª… í˜•ì‹ - YYYYMMDD_hhmmss_countrycode_mallname.csv
        base_filename = f"{date_str}_{time_str}_{country_code}_{mall_name}"

        results = {
            'db_saved': False,
            'server_uploaded': False
        }

        # DB ì €ì¥
        if save_db:
            results['db_saved'] = self.save_to_db(df)

        # íŒŒì¼ì„œë²„ ì—…ë¡œë“œ
        if upload_server:
            try:
                # CSV íŒŒì¼
                temp_csv = f'temp_{base_filename}.csv'
                df.to_csv(temp_csv, index=False, encoding='utf-8-sig')

                remote_csv_filename = f'{base_filename}.csv'
                if self.upload_to_file_server(temp_csv, remote_csv_filename, date_str):
                    results['server_uploaded'] = True

                # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                if os.path.exists(temp_csv):
                    os.remove(temp_csv)

                logger.info("ğŸ—‘ï¸ ì„ì‹œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ")

            except Exception as e:
                logger.error(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

        return results

    def scrape_urls(self, urls_data, max_items=None):
        """ì—¬ëŸ¬ URL ìŠ¤í¬ë˜í•‘"""
        if max_items:
            urls_data = urls_data[:max_items]

        logger.info(f"\n{'='*80}")
        logger.info(f"ğŸ“Š í¬ë¡¤ë§ ì‹œì‘")
        logger.info(f"ğŸ“Œ êµ­ê°€: {self.country_code.upper()}")
        logger.info(f"ğŸ“Œ ëŒ€ìƒ: {len(urls_data)}ê°œ ì œí’ˆ")
        logger.info(f"{'='*80}\n")

        if not self.setup_driver():
            logger.error("ë“œë¼ì´ë²„ ì„¤ì • ì‹¤íŒ¨")
            return None

        results = []
        failed_urls = []

        try:
            for idx, row in enumerate(urls_data):
                logger.info(f"\nì§„í–‰ë¥ : {idx + 1}/{len(urls_data)} ({(idx + 1)/len(urls_data)*100:.1f}%)")

                url = row.get('url')

                # ì œí’ˆ ì •ë³´ ì¶”ì¶œ
                result = self.extract_product_info(url, row)

                # ì‹¤íŒ¨ íŒë‹¨
                if result['retailprice'] is None and result['title'] is None:
                    failed_urls.append({
                        'url': url,
                        'item': row.get('item', ''),
                        'brand': row.get('brand', ''),
                        'reason': 'ê°€ê²©ê³¼ ì œëª© ëª¨ë‘ ì—†ìŒ'
                    })
                elif result['retailprice'] is None:
                    failed_urls.append({
                        'url': url,
                        'item': row.get('item', ''),
                        'brand': row.get('brand', ''),
                        'reason': 'ê°€ê²© ì—†ìŒ'
                    })

                results.append(result)

                # 10ê°œë§ˆë‹¤ ì¤‘ê°„ ì €ì¥
                if (idx + 1) % 10 == 0:
                    interim_df = pd.DataFrame(results[-10:])
                    if self.db_engine:
                        try:
                            table_name = f'amazon_price_crawl_tbl_{self.country_code}_v2'
                            interim_df.to_sql(table_name, self.db_engine,
                                            if_exists='append', index=False)
                            logger.info(f"ğŸ’¾ ì¤‘ê°„ ì €ì¥: 10ê°œ ë ˆì½”ë“œ DB ì €ì¥")
                        except Exception as e:
                            logger.error(f"ì¤‘ê°„ ì €ì¥ ì‹¤íŒ¨: {e}")

                # ë‹¤ìŒ ìš”ì²­ ì „ ëŒ€ê¸°
                if idx < len(urls_data) - 1:
                    wait_time = random.uniform(5, 10)
                    logger.info(f"â³ {wait_time:.1f}ì´ˆ ëŒ€ê¸° ì¤‘...")
                    time.sleep(wait_time)

                    # 20ê°œë§ˆë‹¤ ê¸´ íœ´ì‹
                    if (idx + 1) % 20 == 0:
                        logger.info("â˜• 20ê°œ ì²˜ë¦¬ ì™„ë£Œ, 30ì´ˆ íœ´ì‹...")
                        time.sleep(30)

        except Exception as e:
            logger.error(f"âŒ ìŠ¤í¬ë˜í•‘ ì¤‘ ì˜¤ë¥˜: {e}")

        finally:
            # ì‹¤íŒ¨ URL ìš”ì•½
            if failed_urls:
                logger.warning(f"\nâš ï¸ ë¬¸ì œ ë°œìƒí•œ URL {len(failed_urls)}ê°œ:")
                for fail in failed_urls[:5]:
                    logger.warning(f"  - {fail['brand']} {fail['item']}: {fail.get('reason', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                if len(failed_urls) > 5:
                    logger.warning(f"  ... ì™¸ {len(failed_urls) - 5}ê°œ")

            # ë“œë¼ì´ë²„ ì¢…ë£Œ
            if self.driver:
                self.driver.quit()
                logger.info("ğŸ”§ ë“œë¼ì´ë²„ ì¢…ë£Œ")

        return pd.DataFrame(results)

    def analyze_results(self, df):
        """ê²°ê³¼ ë¶„ì„"""
        logger.info(f"\n{'='*80}")
        logger.info("ğŸ“Š ê²°ê³¼ ë¶„ì„")
        logger.info(f"{'='*80}")

        total = len(df)
        with_price = df['retailprice'].notna().sum()
        without_price = df['retailprice'].isna().sum()
        zero_price = (df['retailprice'] == 0).sum()
        success_rate = (with_price / total * 100) if total > 0 else 0

        logger.info(f"ì „ì²´ ì œí’ˆ: {total}ê°œ")
        logger.info(f"ê°€ê²© ì¶”ì¶œ ì„±ê³µ: {with_price}ê°œ")
        logger.info(f"ê°€ê²© ì¶”ì¶œ ì‹¤íŒ¨: {without_price}ê°œ")
        logger.info(f"ê°€ê²© 0 (íŒë§¤ì ì •ë³´ ì—†ìŒ): {zero_price}ê°œ")
        logger.info(f"ì„±ê³µë¥ : {success_rate:.1f}%")

        if with_price > 0:
            price_df = df[df['retailprice'].notna()].copy()

            # 0ì´ ì•„ë‹Œ ê°€ê²©ë§Œìœ¼ë¡œ í†µê³„ ê³„ì‚°
            non_zero_price_df = price_df[price_df['retailprice'] > 0]

            if not non_zero_price_df.empty:
                logger.info(f"\nğŸ’° ê°€ê²© í†µê³„ (0 ì œì™¸):")
                logger.info(f"   í‰ê· ê°€: {non_zero_price_df['retailprice'].mean():.2f}")
                logger.info(f"   ìµœì €ê°€: {non_zero_price_df['retailprice'].min():.2f}")
                logger.info(f"   ìµœê³ ê°€: {non_zero_price_df['retailprice'].max():.2f}")
                logger.info(f"   ì¤‘ê°„ê°’: {non_zero_price_df['retailprice'].median():.2f}")

            # ë¸Œëœë“œë³„ ì„±ê³µë¥ 
            brand_stats = df.groupby('brand').agg({
                'retailprice': ['count', lambda x: x.notna().sum()]
            })
            brand_stats.columns = ['total', 'success']
            brand_stats['success_rate'] = (brand_stats['success'] / brand_stats['total'] * 100).round(1)

            logger.info(f"\nğŸ“Š ë¸Œëœë“œë³„ ì„±ê³µë¥ :")
            for brand, row in brand_stats.iterrows():
                logger.info(f"   {brand}: {row['success_rate']:.1f}% ({row['success']}/{row['total']})")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ êµ­ê°€ ì½”ë“œ ì½ê¸°
    country_code = os.getenv('COUNTRY_CODE', 'jp').lower()
    test_mode = os.getenv('TEST_MODE', 'false').lower() == 'true'
    max_items = int(os.getenv('MAX_ITEMS', '0')) or None

    print(f"\n{'='*80}")
    print(f"ğŸš€ Amazon ì¼ë³¸ ê°€ê²© ì¶”ì¶œ ì‹œìŠ¤í…œ V2 (íƒ€ì„ì¡´ ë¶„ë¦¬ + ë‚ ì§œë³„ ZIP)")
    print(f"{'='*80}")
    print(f"ğŸ“Œ êµ­ê°€: {country_code.upper()}")
    print(f"ğŸ“Œ ëª¨ë“œ: {'í…ŒìŠ¤íŠ¸' if test_mode else 'ì‹¤ì œ'}")
    if max_items:
        print(f"ğŸ“Œ ìµœëŒ€ ì²˜ë¦¬ ìˆ˜: {max_items}ê°œ")
    print(f"ğŸ“Œ ê°œì„ ì‚¬í•­:")
    print(f"   - ì¼ë³¸ ì‹œê°„ + í•œêµ­ ì‹œê°„ ë¶„ë¦¬ ì €ì¥")
    print(f"   - ë‚ ì§œë³„ ë””ë ‰í† ë¦¬ êµ¬ì¡° (/jp/YYYYMMDD/)")
    print(f"   - ë‚ ì§œë³„ ìë™ ZIP ì••ì¶• (/jp/YYYYMMDD.zip)")
    print(f"   - ìƒˆ ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© (samsung_ds_retail_com)")
    print(f"{'='*80}\n")

    # ìŠ¤í¬ë˜í¼ ì´ˆê¸°í™”
    scraper = AmazonScraper(country_code)

    if scraper.db_engine is None:
        logger.error("DB ì—°ê²° ì‹¤íŒ¨ë¡œ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    # í…ŒìŠ¤íŠ¸ ëª¨ë“œ
    if test_mode:
        logger.info("ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì‹¤í–‰ ì¤‘...")
        test_data = [{
            'url': 'https://www.amazon.co.jp/dp/B0CTRXBKHP',
            'brand': 'Crucial',
            'item': 'T705 1TB',
            'retailerid': 'TEST001',
            'retailersku': 'TEST001',
            'channel': 'Online',
            'seg_lv1': 'SSD',
            'seg_lv2': 'Consumer',
            'seg_lv3': 'NVMe',
            'capacity': '1TB',
            'form_factor': 'M.2'
        }]

        results_df = scraper.scrape_urls(test_data)
        if results_df is not None and not results_df.empty:
            scraper.analyze_results(results_df)

            # í…ŒìŠ¤íŠ¸ ëª¨ë“œì—ì„œëŠ” íŒŒì¼ë§Œ ì €ì¥ (DB ì €ì¥ ì•ˆí•¨)
            scraper.save_results(results_df, save_db=False, upload_server=True)
        return

    # ì‹¤ì œ í¬ë¡¤ë§
    logger.info("ğŸ“Š ì „ì²´ í¬ë¡¤ë§ ì‹œì‘")
    urls_data = scraper.get_crawl_targets(limit=max_items)

    if not urls_data:
        logger.warning("í¬ë¡¤ë§ ëŒ€ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    logger.info(f"âœ… í¬ë¡¤ë§ ëŒ€ìƒ: {len(urls_data)}ê°œ")

    # í¬ë¡¤ë§ ì‹¤í–‰
    results_df = scraper.scrape_urls(urls_data, max_items)

    if results_df is None or results_df.empty:
        logger.error("í¬ë¡¤ë§ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ê²°ê³¼ ë¶„ì„
    scraper.analyze_results(results_df)

    # ê²°ê³¼ ì €ì¥
    save_results = scraper.save_results(
        results_df,
        save_db=True,
        upload_server=True
    )

    logger.info(f"\n{'='*80}")
    logger.info("ğŸ“Š ì €ì¥ ê²°ê³¼")
    logger.info(f"{'='*80}")
    logger.info(f"DB ì €ì¥: {'âœ… ì„±ê³µ' if save_results['db_saved'] else 'âŒ ì‹¤íŒ¨'}")
    logger.info(f"íŒŒì¼ì„œë²„ ì—…ë¡œë“œ: {'âœ… ì„±ê³µ' if save_results['server_uploaded'] else 'âŒ ì‹¤íŒ¨'}")

    logger.info(f"\n{'='*80}")
    logger.info("âœ… í¬ë¡¤ë§ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ! (V2)")
    logger.info(f"   ğŸ¯ íƒ€ì„ì¡´ ë¶„ë¦¬: ì¼ë³¸ ì‹œê°„ + í•œêµ­ ì‹œê°„")
    logger.info(f"   ğŸ“ ë‚ ì§œë³„ ë””ë ‰í† ë¦¬ ì €ì¥")
    logger.info(f"   ğŸ“¦ ìë™ ZIP ì••ì¶•")
    logger.info(f"{'='*80}\n")

if __name__ == "__main__":
    # í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸
    required_packages = [
        'undetected-chromedriver',
        'selenium',
        'pandas',
        'pymysql',
        'sqlalchemy',
        'paramiko',
        'openpyxl'
    ]

    print("\nğŸ“¦ í•„ìš”í•œ íŒ¨í‚¤ì§€:")
    print("pip install " + " ".join(required_packages))
    print("\nâš ï¸ í™˜ê²½ë³€ìˆ˜ ì„¤ì •:")
    print("export COUNTRY_CODE=jp")
    print("export TEST_MODE=false  # í…ŒìŠ¤íŠ¸ ëª¨ë“œ")
    print("export MAX_ITEMS=10     # ìµœëŒ€ ì²˜ë¦¬ ê°œìˆ˜ (ì„ íƒì‚¬í•­)")
    print("\nğŸ¯ V2 ë²„ì „ ê°œì„ ì‚¬í•­:")
    print("- ì¼ë³¸ í‘œì¤€ì‹œ(JST) + í•œêµ­ í‘œì¤€ì‹œ(KST) ë¶„ë¦¬ ì €ì¥")
    print("- íŒŒì¼ëª… í˜•ì‹: YYYYMMDD_hhmmss_jp_amazon.csv")
    print("- ë‚ ì§œë³„ ë””ë ‰í† ë¦¬: /jp/YYYYMMDD/")
    print("- ë‚ ì§œë³„ ZIP ì••ì¶•: /jp/YYYYMMDD.zip")
    print("- ìƒˆ ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸”: amazon_price_crawl_tbl_jp_v2")
    print()

    main()
